# redis面试题

## 1. 通用问题

### 1.使用 Redis 有哪些好处？

1. **速度快**，因为数据存在内存中，类似于 HashMap，HashMap 的优势就是**查找和操作的时间复杂度都是 （O1）**
2. 支持**丰富数据类型**，支持 **string，list，set，Zset，hash** 等 
3. 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行。
4. 丰富的特性：可用于缓存，消息，按 key 设置过期时间，过期后将会自动删除。



### 2. Memcache 与 Redis 的区别都有哪些？  



1. 存储方式 Memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis 有部份存在硬盘上，这样能保证数据的持久性。
2. 数据支持类型 Memcache 对数据类型支持相对简单。 Redis 有复杂的数据类型。
3. 使用底层模型不同 它们之间底层实现方式以及与客户端之间通信的应用协议不一样。 Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。  
4. Redis 是单线程，Memcached 是多线程，在存储大数据的情况下，Redis 比 Memcached 稍有逊色。
5. Memcached 没有原生的集群模式，Redis 官方支持 Redis Cluster 集群模式



### 3. 一个字符串类型的值能存储最大容量是多少？  



512M。

### 4.Redis 过期键的删除策略？  



 （1）**定时删除:** 在设置键的过期时间的同时，创建一个定时器 timer). 让定时器在键的过期时间来临时，立即执行对键的删除操作。 



（2）**惰性删除:** 放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键;如果没有过期，就返回该键。 



（3）**定期删除:** 每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。  



### 5. Pipeline 有什么好处，为什么要用 Pipeline？  



**可以将多次 IO 往返的时间缩减为一次，前提是 pipeline 执行的指令之间没有因果相关性。**使用 Redis-benchmark 进行压测的时候可以发现影响 Redis 的 QPS 峰值的一个重要因素是 pipeline 批次指令的数目。  



开启 Redis pipeline 之后,再执行 Redis 的其他命令，命令将不会发送给服务端，而是先暂存在客户端，左后等到所有命令都执行完，然后再统一发送给服务端。



服务端会根据发送过来的命令的顺序，依次运行计算。



然后同样先将结果暂存服务端，等到命令都执行完毕之后，统一返回给客户端。



**通过这种方式，减少多个命令之间网络交互，有效的提高多个命令执行的速度。**



### 6.Redis key 的过期时间和永久有效分别怎么设置？



EXPIRE 和 PERSIST 命令。  



### 7.一个 Redis 实例最多能存放多少的 keys？ List、Set、 Sorted Set 他们最多能存放多少元素？  



理论上 Redis 可以处理多达 2的32次方的 keys，并且在实际中进行了测试，每个实 例至少存放了 2 亿 5 千万的 keys。我们正在测试一些较大的值。任何 list、 set、和 sorted set 都可以放 2的32次方个元素。换句话说，Redis 的存储极限是系统中的可用内存值。  





### 8.假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？  



使用 keys 指令可以扫出指定模式的 key 列表。 

对方接着追问：如果这个 Redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？



 这个时候你要回答 Redis 关键的一个特性：Redis 的单线程的。keys 指令会 导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。



这个时候可以使用 scan 指令，**scan 指令可以无阻塞的提取出指定模式的 key 列表**，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。  

## 

### 9.使用过 Redis 做异步队列么，你是怎么用的？  



 一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。 



**如果对方追问可不可以不 用 sleep 呢？** 

list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。



**如果对方追问能不能生产一次消费多次呢？** 

使用 pub/sub 主题订 阅者模式，可以实现 1:N 的消息队列。

 

**如果对方追问 pub/sub 有什么缺点？** 

在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 RabbitMQ 等。



**如果对方追问 Redis 如何实现延时队列？** 



我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的 这么详细。但是你很克制，然后神态自若的回答道：使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。  



## 2. 基础架构



### 1. redis架构图



![img](https://cdn.nlark.com/yuque/0/2022/jpeg/22228669/1642799043449-8ac58914-ac69-476f-b14e-de68cf8ef0cb.jpeg?x-oss-process=image%2Fresize%2Cw_1773%2Climit_0)

Redis 主要通过网络框架进行访问，而不再是动态库了，这也使得 Redis 可以作为一个基础性的网络服务进行访问，扩大了Redis 的应用范围。 

Redis 数据模型中的 value 类型很丰富，因此也带来了更多的操作接口，例如面向列表的 LPUSH/LPOP，面向集合的 SADD/SREM 等。

Redis 的持久化模块能支持两种方式：日志（AOF）和快照（RDB），这两种持久化方式具有不同的优劣势，影响到 Redis 的访问性能和可靠性。

SimpleKV 是个简单的单机键值数据库，但是，Redis 支持高可靠集群和高可扩展集群，因此，Redis 中包含了相应的集群功能支撑模块。 

### 2. redis数据结构图



简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642800586503-03b3be6e-dc61-48bd-8a7d-cbff47de62c5.png)

可以看到，String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、 Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据。  

### 3. 全局哈希表是什么?

为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。  

 一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642801047995-8dab28e8-a0f3-411b-80eb-4f2b94cbd7ca.png)

### 4. **Rehash**是什么?



**rehash 也就是增加现有的哈希桶数量，让逐渐 增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。**  



Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。

一开始，当你刚插入数据时，默认使用哈希表1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：



\1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；



\2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中； 



\3. 释放哈希表 1 的空间。  



到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。 



**Redis 采用了渐进式 rehash。** 简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。



### 5. 不同底层数据结构的操作效率



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642802047775-d36394cc-0342-4227-9bd7-ee436ea150a7.png)



### 6. Strings类型的内存开销



当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数， 这种保存方式通常也叫作 int 编码方式。 



但是，当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643087950400-954541fb-413d-40d1-bf52-214e9469ca2e.png)

**buf：字节数组，保存实际数据。**为了表示字节数组的结束，Redis 会自动在数组最后加 一个“\0”，这就会额外占用 1 个字节的开销。 



**len：占 4 个字节**，表示 buf 的已用长度。



**alloc：也占个 4 字节**，表示 buf 的实际分配长度，一般大于 len。  



另外，**对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构 体的开销。** 



因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最 后一次访问的时间、被引用的次数等），所以，**Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据**。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643088066602-87b0e090-5c6c-493e-8ff4-33bc3d20af42.png)



另外， Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是 一个 dictEntry 的结构体，用来指向一个键值对。**dictEntry结构体也会有额外的内存开销。**



 dictEntry 结构中有三个 8 字节的指针， 分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图所示：  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643088193557-91675455-fca5-4689-a3f6-b6a1182e08db.png)

但是，在保存的键值对本身占用的内存空间不大时（例如这节课里提到的的 图片 ID 和图片存储对象 ID），String 类型的元数据开销就占据主导了，**这里面包括了 RedisObject 结构、SDS 结构、dictEntry 结构的内存开销**。  



**针对这种情况，我们可以使用压缩列表保存数据。**当然，使用 Hash 这种集合类型保存单值键值对的数据时，我们需要将单值数据拆分成两部分，分别作为 Hash 集合的键和值。

 

### 7. 集合统计模式

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643089825724-884c612d-0d84-4e06-884c-79c695725bc1.png?x-oss-process=image%2Fresize%2Cw_750%2Climit_0)



### 8. 如何实现新的数据类型?



GEO 属于 Redis 提供的扩展数据类型。

扩展数据类型有两种实现途径：**一种是基于现有的数据类型，通过数据编码或是实现新的操作的方式，来实现扩展数据类型，**例如基于 Sorted Set 和 GeoHash 编码实现 GEO，以及基于 String 和位操作实现 Bitmap；

**另一种就是开发自定义的数据类型，具体的操作是增加新数据类型的定义，实现创建和释放函数，实现新数据类型支持的命令操作**.



### 9. 时间序列数据应该采用什么数据结构?



第一种方案是，**组合使用 Redis 内置的 Hash 和 Sorted Set 类型**，把数据同时保存在 Hash 集合和 Sorted Set 集合中。这种方案既可以利用 Hash 类型实现对单键的快速查询，还能利用 Sorted Set 实现对范围查询的高效支持，一下子满足了时间序列数据的两大查询需求。 需要利用事务保证数据一致性。



不过，第一种方案也有两个不足：一个是，在执行聚合计算时，我们需要把数据读取到客户端再进行聚合，当有大量数据要聚合时，数据传输开销大；另一个是，所有的数据会在 两个数据类型中各保存一份，内存开销不小。

不过，我们可以通过设置适当的数据过期时间，释放内存，减小内存压力。 



**我们学习的第二种实现方案是使用 RedisTimeSeries 模块**。这是专门为存取时间序列数据 而设计的扩展模块。和第一种方案相比，RedisTimeSeries 能支持直接在 Redis 实例上进 行多种数据聚合计算，避免了大量数据在实例和客户端间传输。不过，RedisTimeSeries 的底层数据结构使用了链表，它的范围查询的复杂度是 O(N) 级别的，同时，它的 TS.GET 查询只能返回最新的数据，没有办法像第一种方案的 Hash 类型一样，可以返回任一时间点的数据。 所以，组合使用 Hash 和 Sorted Set，或者使用 RedisTimeSeries，在支持时间序列数据 存取上各有优劣势。



**如果部署环境中网络带宽高、Redis 实例内存大，可以优先考虑第一种方案；**  

**如果部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案。**  



### 10. redis的单线程指的是什么?



我们通常说，Redis 是单线程，**主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。** 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。  



### 11. 单线程 Redis 为什么那么快？



 一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。



另一方面，就是 Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。  



### 12. 基于多路复用的高性能 I/O 模型是怎样的?



**Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。**简单来说，在 Redis 只运行单线程的情况下，**该机制允许内核中，同时存在多个监听套接字和已连接套接字。**内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。 



下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。 Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理 上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。 

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642804026075-3e14b1b2-90ea-4816-9211-8df7de78c6e1.png)

基于多路复用的Redis高性能IO模型 为了在请求到达时能通知到 Redis 线程，select/epoll 提供了**基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。** 



那么，回调机制是怎么工作的呢？其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。 



这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来， Redis无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时， Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件 的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。  

## 3. 持久化



### 1. AOF日志的实现流程



AOF 日志和WAL正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入 内存，然后才记录日志，如下图所示：  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642804560701-38b7891e-117d-4031-9e07-2bfb78bd3592.png)

而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志 中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处 是，可以避免出现记录错误命令的情况。 除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。  (**最终的目的应该还是追求高性能**)



**两个风险:**



首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。



其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因 为，AOF日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。  



**三种回写策略:**

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642804853616-103e6421-e336-494d-9d30-15759a34fcdd.png)

### 2. 什么是AOF重写日志?



为了避免日志文件过大，Redis 还提供了 AOF 重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642805180136-efe8bb5c-2f7d-4370-b7f7-657391ee6ca7.png)

总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个 日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行 数据重写，所以，这个过程并不会阻塞主线程。  



### 3. AOF日志持久化有哪些优缺点?



**优点：**



1. 数据安全，aof 持久化可以配置 append fsync 属性，有 always，每进行一次命令操作就记录到 aof 文件中一次。
2. 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。
3. AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall)



**缺点：**



1. AOF 文件比 RDB 文件大，且恢复速度慢。 
2. 数据集大的时候，比 rdb 启动效率低。



### 4. 什么是RDB内存快照



RDB是Redis用来进行持久化的一种方式，是把当前内存中的数据集快照写入磁盘，也就是 Snapshot 快照（数据库中所有键值对数据）。恢复时是将快照文件直接读到内存里。



Redis 提供了两个命令来生成 RDB 文件，**分别是 save 和 bgsave。**



save：在主线程中执行，会导致阻塞；

bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。 **我们应该使用bgsave这种方式。**



好了，这个时候，我们就可以通过 bgsave 命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对 Redis 的性能影响.

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642806125301-6275c7fc-a2bd-4f34-832b-81ae5de5273e.png)

当执行快照时,Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW）正常处理写操作

如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。

### 

### 5. 使用RDB内存快照有哪些开销



1. 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
2. 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。  



### 6. AOF与RDB使用总结



内存快照方法的**优势**在于可以快速恢复数据库，也就是只需要把 RDB 文件直接读入内存，这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。 



不过，内存快照也有它的**局限性**。它拍的是一张内存的“大合影”，不可避免地会耗时耗力。虽然，Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。



而混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。



最后，关于 AOF 和 RDB 的选择问题，我想再给你提**三点建议：** 



1.数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；

2.如果允许分钟级别的数据丢失，可以只使用 RDB；

3.如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。  

## 4. 并发访问

### 1.如何保证原子操作



Redis 提供了两种原子操作的方法来实现并发控制，分别是**单命令操作和 Lua 脚本**。因为 原子操作本身不会对太多的资源限制访问，可以维持较高的系统并发性能。  



但是，单命令原子操作的适用范围较小，并不是所有的 RMW 操作都能转变成单命令的原子操作（例如 INCR/DECR 命令只能在读取数据后做原子增减），当我们需要对读取的数据做更多判断，或者是我们对数据的修改不是简单的增减时，单命令操作就不适用了。  



而 Redis 的 Lua 脚本可以包含多个操作，这些操作都会以原子性的方式执行，绕开了单命令操作的限制。不过，如果把很多操作都放在 Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis 的并发性能。所以，我给你一个小建议：**在编写 Lua 脚本时，你要避免把不需要做并发控制的操作写入脚本中。**  



### 2.如何实现分布式锁



**单实例实现**



分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储系统发送命令进行加 锁或释放锁操作。Redis 作为一个共享存储系统，可以用来实现分布式锁。  



**在基于单个 Redis 实例实现分布式锁时，对于加锁操作，我们需要满足三个条件。**  



加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；  



锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；  



锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端。  



和加锁类似，释放锁也包含了读取锁变量值、判断锁变量值和删除锁变量三个操作，不过，我们无法使用单个命令来实现，所以，我们可以采用 Lua 脚本执行释放锁操作，通过 Redis 原子性地执行 Lua 脚本，来保证释放锁操作的原子性。  



不过，基于单个 Redis 实例实现分布式锁时，会面临实例异常或崩溃的情况，这会导致实例无法提供锁操作，正因为此，Redis 也提供了 Redlock 算法，用来实现基于多个实例的分布式锁。这样一来，锁变量由多个实例维护，即使有实例发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。Redlock 算法是实现高可靠分布式锁的一种有效解决 方案，你可以在实际应用中把它用起来。  



**代码：**

```go
//加锁
SET lock_key unique_value NX PX 10000

//解锁
//
if redis.call("get",KEYS[1]) == ARGV[1] then
	return redis.call("del",KEYS[1])
else
    return 0
end
```



**Redlock算法思路**



Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。  



我们来具体看下 Redlock 算法的执行步骤。Redlock 算法的实现需要有 N 个独立的 Redis 实例。接下来，我们可以分成 3 步来完成加锁操作。 



**第一步是，客户端获取当前时间。**



**第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作。**  

 

这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX/PX 选 项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间。  



如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。  



**第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。**



客户端只有在满足下面的这两个条件时，才能认为是加锁成功。  



条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁； 



条件二：客户端获取锁的总耗时没有超过锁的有效时间。  



### 3.redis中的事务

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643989540245-645a68a6-0cb4-42e8-adaf-4f277b85077e.png)

事务的 ACID 属性是我们使用事务进行正确操作的基本要求。通过这节课的分析，我们了 解到了，Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、 一致性和隔离性这三个属性。 

原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其 它情况下，事务都可以原子性执行。（**事务是不会进行回滚的!**）



所以，我给你一个小建议：严格按照 Redis 的命令规范进行程序开发，**并且通过 code review 确保命令的正确性。**这样一来，Redis 的事务机制就能被应用在实践中，保证多操作的正确执行。



### 4.redis事务为何不支持回滚



redis命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或者是命令用在了错误类型的键上面。也就是说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。



因为不需要对回滚进行支持，所以redis的内部可以保持简单快速。



鉴于没有任何机制能够避免程序员自己造成的错误，并且这类错误通常不会在生产环境中出现，所以redis选择了更简单、更快速的无回滚方式来处理事务。

## 5. 性能



### 1.Redis 内部的阻塞式操作有哪些



**五个阻塞点：集合全量查询和聚合操作； bigkey 删除； 清空数据库； AOF 日志同步写(AOF不要每次都落盘)； 从库加载 RDB 文件。**  



在这 5 大阻塞点中，bigkey 删除、清空数据库、AOF 日志同步写不属于关键路径操作，可以使用异步子线程机制来完成。Redis 在运行时会创建三个子线程，主线程会通过一个任务队列和三个子线程进行交互。子线程会根据任务的具体类型，来执行相应的异步操作。  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643184219637-b01ba0ec-e206-455c-a805-6fafd6672cf4.png)



### 2.CPU 核和 NUMA 架构的影响



如果在 CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对 Redis 实例的请求处理时间影响就更大了。**每调度一次，一些请求就会受到运行时信息、 指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。**  



### 3.如何判断redis变慢



**1. 查看 Redis 的响应延迟**  

 

如果Redis 命令的执行时间突然就增长到了几秒，基本就可以认定 Redis 变慢了。这种是看延迟的绝对值。



**2.当前环境下的 Redis 基线性能**  



实际上，从 2.8.7 版本开始，redis-cli 命令提供了–intrinsic-latency 选项，可以用来**监测和统计测试期间内的最大延迟，这个延迟可以作为 Redis 的基线性能。**其中，测试时长可以用–intrinsic-latency 选项的参数来指定。  



需要注意的是，基线性能和当前的操作系统、硬件配置相关。因此，我们可以把它和 Redis 运行时的延迟结合起来，再进一步判断 Redis 性能是否变慢了。  



 一般来说，你要把运行时延迟和基线性能进行对比，如果你观察到的 Redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了。  

### 4.Redis 内存碎片是什么



虽然操作系统的剩余内存空间总量足够，但是，应用申请的是一块连续地址空间的 N 字节，但在剩余的内存空间中，没有大小为 N 字节的连续空间了，那么，这些剩余空间就是内存碎片（比如上图中的“空闲 2 字节”和“空闲 1 字节”，就是这样的碎片）。 

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643215288205-c0d134f1-aebe-45f7-8a15-bf4d3fda6dce.png)

### 5.为什么会产生内存碎片？

**内因：内存分配器的分配策略**



Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，**默认使用 jemalloc。**



jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字 节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值 时，jemalloc 会给它分配相应大小的空间。 这样的分配方式本身是为了减少分配次数。例如，Redis 申请一个 20 字节的空间保存数 据，jemalloc 就会分配 32 字节，此时，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了，因为刚才分配的 32 字节已经够用了，这就避免了一次分配操作。 但是，如果 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 Redis 的外因了。  



**外因：键值对大小不一样和删改操作**



Redis 通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在 Redis 中，这就会带来不同大小的键值对。这样一来，Redis 申请内存空间分配时，本身就会有大小不一的空间需求。这是第一个外因。  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643215517257-c91779c1-5a59-4948-b52a-3f8b3393b264.png)



第二个外因是，**这些键值对会被修改和删除，这会导致空间的扩容和释放。**具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。 另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643215547997-995d9c2f-78c6-48c7-bc4d-a989ab999eab.png)

### 6.如何清理内存碎片?



**1.重启 Redis 实例** ,但这会导致长时间无法提供服务。



**2. 内存碎片自动清理。**但是会导致redis性能变慢，有两个可调控的参数： 



active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展； active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致 响应延迟升高。  



### 7.Redis 缓冲区是什么



缓冲区的功能其实很简单，主要就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。但因为缓冲区的内存空间有限，如果往里面写入数据的速度持续地大于从里面读取数据的速度，就会导致缓冲区需要越来越多的内存来暂存数据。当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出。  



## 6. 缓存



### 1.缓存的类型有哪些



**只读缓存**



当 Redis 用作只读缓存时，应用要读取数据的话，会先调用 Redis GET 接口，查询数据是否存在。而所有的数据写请求，会直接发往后端的数据库，在数据库中增删改。



对于删改的数据来说，如果 Redis 已经缓存了相应的数据，应用需要把这些缓存的数据删除，Redis 中就没有这些数据了。 当应用再次读取这些数据时，会发生缓存缺失，应用会把这些数据从数据库中读出来，并写到缓存中。这样一来，这些数据后续再被读取时，就可以直接从缓存中获取了，能起到加速访问的效果。  



**读写缓存**



知道了只读缓存，读写缓存也就很容易理解了。  



对于读写缓存来说，除了读请求会发送到缓存进行处理（直接在缓存中查询数据是否存 在)，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。此时，得益于 Redis 的高性能访问特性，数据的增删改操作可以在缓存中快速完成，处理结果也会快速 返回给业务应用，这就可以提升业务应用的响应速度。 



但是，和只读缓存不一样的是，在使用读写缓存时，最新的数据是在 Redis 中，而 Redis 是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新 数据可能会丢失，给应用业务带来风险。



所以，根据业务应用对数据可靠性和缓存性能的不同要求，我们会有**同步直写和异步写回两种策略**。其中，同步直写策略优先保证数据可靠性，而异步写回策略优先提供快速响应。学习了解这两种策略，可以帮助我们根据业务需求，做出正确的设计选择。  



同步直写是指，写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。这样，即使缓存宕机或发生故障，最新的数据仍然保存在数据库中，这就提供了数据可靠性保证。  



而异步写回策略，则是优先考虑了响应延迟。此时，所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。这样一来，处理这些数据的操作是在缓存中进行的，很快就能完成。只不过，如果发生了掉电，而它们还没有被写回数据库，就会有丢失的风险了。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643895396638-0af72b13-ca4c-409b-8f9a-e824d5e69822.png)



关于是选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求。  



如果需要对写请求进行加速，我们选择读写缓存； 



如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。   



举个例子，在商品大促的场景中，商品的库存信息会一直被修改。如果每次修改都需到数据库中处理，就会拖慢整个应用，此时，我们通常会选择读写缓存的模式。而在短视频 App 的场景中，虽然视频的属性有很多，但是，一般确定后，修改并不频繁，此时，在数据库中进行修改对缓存影响不大，所以只读缓存模式是一个合适的选择。



### 2.缓存淘汰策略



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643896095873-e44b8020-5668-4b6c-8456-bcc7a912525b.png)



**noeviction**

默认情况下，Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，也就是设定的 noeviction 策略。对应到 Redis 缓存，也就是指，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。  



**volatile-ttl**  

在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。  



**volatile-random**  

就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。  



**volatile-lru**  

使用 LRU 算法筛选设置了过期时间的键值对。  



**volatile-lfu**  

使用 LFU算法筛选设置了过期时间的键值对。  



**allkeys-random**  

从所有键值对中随机选择并删除数据；  



**allkeys-lru**  

使用 LRU 算法在所有数据中进行筛选。  



**allkeys-lfu**  

使用 LFU 算法在所有数据中进行筛选。  



**策略使用建议**



优先使用 allkeys-lru 策略。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。 



如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用 allkeys-random 策略，随机选择淘汰的数据就行。 



如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。  



### 3.redis中如何实现的LRU算法



**LRU 算法的全称是 Least Recently Used，从名字上就可以看出，这是按照最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。**  



那具体是怎么筛选的呢？LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643897131518-2ba5383e-632d-4697-aa2b-ade5ec88d103.png)



其实，LRU 算法背后的想法非常朴素：它认为刚刚被访问的数据，肯定还会被再次访问， 所以就把它放在 MRU 端；长久不访问的数据，肯定就不会再被访问了，所以就让它逐渐后移到 LRU 端，在缓存满时，就优先删

它。  



不过，LRU 算法在实际实现时，**需要用链表管理所有的缓存数据，这会带来额外的空间开销**。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。  



所以，在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，**Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。**然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。  



Redis 提供了一个配置参数 maxmemory-samples，这个参数就是 Redis 选出的数据个数 N。例如，我们执行如下命令，可以让 Redis 选出 100 个数据作为候选数据集：  

```go
CONFIG SET maxmemory-samples 100
```



当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：**能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值**。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemorysamples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。  



这样一来，Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。  

### 

### 4.redis中如何实现的LFU算法



**Least frequently used(最不常用的)**

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。  



 在此基础上，**Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一 步拆分成了两部分。**  



 **Idt 值：lru 字段的前 16bit，表示数据的访问时间戳；**

 

**counter 值：lru 字段的后 8bit，表示数据的访问次数。**  



当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。  



**为了避开 8bit 最大只能记录 255 的限制，LFU 策略设计使用非线性增长的计数器来表示数 据的访问次数。**  



此外，如果业务应用中有短时高频访问的数据，除了 LFU 策略本身会对数据的访问次数进 行自动衰减以外，我再给你个小建议：你可以优先使用 volatile-lfu 策略，并根据这些数据访问时限设置它们的过期时间，以免它们留存在缓存中造成污染。    



### 5.如何保证缓存和数据库一致性



**对于读写缓存来说，如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。或者有些业务本身也不一定要求数据是一致的。像上次视频的观看进度，我们就使用了异步写回的策略。**



对于只读缓存，可以参考下图：



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643898729624-33ee7cdc-249c-4033-b4f6-1269a76f1355.png)



 **优先使用先更新数据库再删除缓存的方法，原因主要有两个：**  



 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来 压力；  



 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。 



如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请 求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。     



### 6.缓存异常该如何处理？



从问题成因来看，缓存雪崩 和击穿主要是因为数据不在缓存中了，而缓存穿透则是因为数据既不在缓存中，也不在数据库中。所以，**缓存雪崩或击穿时，一旦数据库中的数据被再次写入到缓存后，应用又可 以在缓存中快速访**问数据了，数据库的压力也会相应地降低下来，而**缓存穿透发生时， Redis 缓存和数据库会同时持续承受请求压力。**  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1643900297245-edd4679c-2fa6-4621-bd33-93f7266fefea.png)



服务熔断、服务降级、请求限流这些方法都是属于“有损”方案， 在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断， 那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制 后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。  



**所以，尽量使用预防式方案：** 



针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；

针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间； 

针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作， 避免误删除。

## 7. 主从与集群



### 1.主从同步的原理是什么？



**Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。**  



**读操作：**主库、从库都可以接收； 

**写操作：**首先到主库执行，然后，主库将写操作同步给从库。  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642944862262-7b8d70d6-1247-47bc-a9b4-a442e58cbcf0.png)



**具体流程**



当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前 使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。



例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上 执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：  

```java
1 replicaof 172.16.19.3 6379
```

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642945312283-9ba61777-767d-4e7c-b562-9ee381188105.png)

 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步， **从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。**

 

具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数 来启动复制。psync 命令包含了**主库的 runID 和复制进度 offset 两个参数。** 



runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实 例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设 为“？”。 



offset，此时设为 -1，表示第一次复制。  



主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库 目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。 这里有个地方需要注意，**FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说， 主库会把当前所有的数据都复制给从库。** 



在第二阶段，**主库将所有数据同步给从库。**从库收到数据后，在本地完成数据加载。这个 过程依赖于内存快照生成的 RDB 文件。  



具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把 当前数据库清空。  



在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则， Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件 中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。  



最后，也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。  



全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。



### 2. 主从级联模式是什么



简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置 较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的 从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。  



 这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的 从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示：  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642946319676-7c014f25-b223-4a69-be36-2cca1f5697cc.png)



 一旦主从库完成了全量复制，它们之间就会一 直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这 个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。  



长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。



### 3. 增量复制



从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。听名字大概 就可以猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。



那么，增量复制时，主从库之间具体是怎么保持同步的呢？这里的奥妙就在于 repl_backlog_buffer 这个缓冲区。我们先来看下它是如何用于增量命令的同步的。  



 repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己 已经读到的位置。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642946404016-bb0d4d92-5f7a-4fd3-b71b-9a9db3f911e0.png)

不过，有一个地方我要强调一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在 缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速 度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库 间的数据不一致。  





### 4. 哨兵机制



Redis 的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低 Redis 集群的运维开销： 

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642947359465-ffccf0e4-180c-4512-a086-50ece40ebdf4.png)

**监控主库运行状态，并判断主库是否客观下线；**



简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判 断主库为“主观下线”，才能最终判定主库为“客观下线”。



**在主库客观下线后，选取新主库；** 



首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符 合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分， 只要有得分最高的从库出现，就把它选为新主库。  



**选出新主库后，通知从库和客户端。**  



为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实 例通过“少数服从多数”的原则，来判断主库是否客观下线。一般来说，我们可以部署三个哨兵，如果有两个哨兵认定主库“主观下线”，就可以开始切换过程。当然，如果你希 望进一步提升判断准确率，也可以再适当增加哨兵个数，比如说使用五个哨兵。  



### 5. 哨兵集群



支持哨兵集群的这些关键机制，包括：  



**基于 pub/sub 机制的哨兵集群组成过程；**  



哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅 机制。  



哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当 多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端 口。



在主从集群中，主库上有一个名为“__sentinel__:hello”的频道，不同哨兵就是通过 它来相互发现，实现互相通信的。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642949672903-9a57e8e2-2790-4b4e-9640-6ae067ad07d6.png)



**基于 INFO 命令的从库列表，这可以帮助哨兵和从库建立连接；**



这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命 令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列 表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642949718432-f63db8a3-2033-43a9-93a4-da52db02a38e.png)

  

**基于哨兵自身的 pub/sub 功能，这实现了客户端和哨兵之间的事件通知。**  



 从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操 作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户 端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过 程中的不同关键事件。  



 从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操 作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户 端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过 程中的不同关键事件。  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642950052818-820cd842-1a3e-4d8f-8ac3-eae6176a0787.png)



**最后:**



 对于主从切换，当然不是哪个哨兵想执行就可以执行的，否则就乱套了。所以，这就需要 哨兵集群在判断了主库“客观下线”后，经过投票仲裁，选举一个 Leader 出来，由它负责 实际的主从切换，即由它来完成新主库的选择以及通知从库与客户端。  



 **要保证所有哨兵实例的配置是一致的，尤其是主观下线 的判断值 down-after-milliseconds**。我们曾经就踩过一个“坑”。当时，在我们的项目 中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库 形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。 



### 6. 主从有可能出现的问题



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1645606261351-de76dbf3-8b5a-4b74-963c-b41dce677cc4.png)

### 7. RedisCluster哈希槽是什么？



具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot）， **来处理数据和实例之间的映射关系。**



在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。 



具体的映射过程分为两大步：首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。关于 CRC16 算法，不是这节课的重点，你简单看下链接中的 资料就可以了。 



那么，这些哈希槽又是如何被映射到具体的 Redis 实例上的呢？ 我们在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例 上的槽个数为 16384/N 个。



当然， 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。  



 **在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。**  



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642951697184-abd323be-50dc-4184-bb5e-a61e766b3b29.png)

 数据、哈希槽、实例这三者的映射分布情况  



### 8. RedisCluster客户端是如何定位数据的？



Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。 客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。



Redis Cluster 方案提供了一种重定向机制，**所谓的“重定向”**，就是指，客户端给一个实 例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。



那客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请 求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就 会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。  

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642952107259-7207a4cd-a3b1-4921-bdda-bf46f112a055.png)

其中，MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642952167105-01ab7d33-45b2-4d85-8301-f12339b320f7.png)

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642952404395-187d8bc9-a0f6-48ca-a27f-702a0cbad34d.png)

![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1642952371137-58b2843c-9fa9-410e-8663-f49e72bc0799.png)

这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。



 和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。



这也就是说， ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。  



### 9. 什么是脑裂？



所谓的脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。



### 10. 为什么会发生脑裂?



脑裂发生的原因主要是原主库发生了假故障，原因主要如下：

1. 和主库部署在同一台服务器上的其他程序临时占**用了大量资源**（例如 CPU 资源），导致主库资源使用受限，**短时间内无法响应心跳**。其它程序不再使用资源时，主库又恢复正常。
2. 主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap，短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。



### 11. 如何解决脑裂?



min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；

min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送ACK 消息的最大延迟（以秒为单位）。



假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。



**这种方法也是有脑裂的风险的。**

### 

### 12. 集群中数据倾斜怎么办?



这节课，我向你介绍了数据倾斜的两种情况：数据量倾斜和数据访问倾斜。 

造成数据量倾斜的原因主要有三个：



\1. 数据中有 bigkey，导致某个实例的数据量增加； 

\2. Slot 手工分配不均，导致某个或某些实例上有大量数据； 

\3. 使用了 Hash Tag，导致数据集中到某些实例上。



而数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上。 

为了应对数据倾斜问题，我给你介绍了四个方法，也分别对应了造成数据倾斜的四个原因。我把它们总结在下表中，你可以看下。



![img](https://cdn.nlark.com/yuque/0/2022/png/22228669/1645955841188-a993594b-3cd4-4bbe-8e6d-69dc7623d3da.png)



当然，如果已经发生了数据倾斜，我们可以通过数据迁移来缓解数据倾斜的影响。RedisCluster 和 Codis 集群都提供了查看 Slot 分配和手工迁移 Slot 的命令，你可以把它们应用起来。 



最后，关于集群的实例资源配置，我再给你一个小建议：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量Slot。

# 操作

## 远程连接

```
redis-cli -h 192.168.1.1 -p 6379
```

# 常见问题

## 容器中使用宿主机的redis

- 可以直接绑定所有网卡，这样来自所有网卡都可连接redis

```
bind 0.0.0.0
```

![image-20220314011903320](http://myimg.go2flare.xyz/img/image-20220314011903320.png)

- 宿主机的conf绑定虚拟网卡的ip

网卡ip

```
127.0.0.1 172.17.0.1 172.18.0.1 172.29.113.151
```

conf中绑定这些网卡，则来自这些ip的连接请求都可通过

```
bind 172.17.0.1 127.0.0.1 172.18.0.1
```

测试结果

```
2022/03/12 10:21:55 redis配置连接成功，network=tcp, address=172.18.0.1:6379, password=4.234.23123

但是redis显示只有绑定一张网卡，所以要不就指定一张，要不就直接全部网卡
```

![image-20220314012458526](http://myimg.go2flare.xyz/img/image-20220314012458526.png)

## 启动redis无法卡在shutdown

- 可以直接过滤进程kill -9即可

```
systemctl restart redisd 
systemctl status redisd -l

● redisd.service - LSB: Redis data structure server
   Loaded: loaded (/etc/rc.d/init.d/redisd; bad; vendor preset: disabled)
   Active: active (exited) since 六 2022-03-12 18:11:55 CST; 7s ago
     Docs: man:systemd-sysv-generator(8)
  Process: 28870 ExecStop=/etc/rc.d/init.d/redisd stop (code=exited, status=0/SUCCESS)
  Process: 28873 ExecStart=/etc/rc.d/init.d/redisd start (code=exited, status=0/SUCCESS)

3月 12 18:11:55 iZwz9afneoimfjfr10i6xzZ systemd[1]: Stopped LSB: Redis data structure server.
3月 12 18:11:55 iZwz9afneoimfjfr10i6xzZ redisd[28870]: Redis stopped
3月 12 18:11:55 iZwz9afneoimfjfr10i6xzZ systemd[1]: Starting LSB: Redis data structure server...
3月 12 18:11:55 iZwz9afneoimfjfr10i6xzZ redisd[28873]: /var/run/redis_6379.pid exists, process is already running or crashed
3月 12 18:11:55 iZwz9afneoimfjfr10i6xzZ systemd[1]: Started LSB: Redis data structure server.

有端口文件占用直接删除即可
rm -f /var/run/redis_6379.pid
```

