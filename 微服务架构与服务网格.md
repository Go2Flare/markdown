# 微服务

## 定义
​       **微服务架构**是将复杂的系统使用组件化的方式进行拆分，并使用轻量级协议通信进行整合的一种设计方法。

​       **微服务**是松散耦合的，可独立部署的，通过微服务架构设计方法拆分出来的一个独立的组件化的小应用，服务一个或者一组相对较小且独立的功能单元，是用户可以感知最小功能集。

​       那么广义上来讲，微服务是一种分布式系统解决方案，推动细粒度服务的使用，这些服务协同工作。

​       微服务架构定义的精髓，可以用一句话来描述，那就是“**分而治之，合而用之**”。将复杂的系统进行拆分的方法，就是“分而治之”。分而治之，可以让复杂的事情变的简单，这很符合我们平时处理问题的方法。 使用轻量级通讯等方式进行整合的设计，就是“合而用之”的方法，合而用之可以让微小的力量变动强大。

## 单体式架构的瓶颈

我们知道，与微服务架构相反的就是单体式架构，我们来看看单体式架构设计的缺点，就更能体会微服务的好处了。

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202405534-1135450495.png)

单体架构在规模比较小的情况下工作情况良好，但是随着系统规模的扩大，它暴露出来的问题也越来越多，主要有以下几点：

1. **复杂性逐渐变高**

   比如有几十万行代码的历史悠久的大型项目，代码越多复杂性越高，越难解决遇到的问题。

2. **技术债务逐渐上升**

   公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑越多，也就是所谓的技术债务越来越多。

3. **耦合度太高，维护成本大**

   当应用程序的功能越来越多、团队越来越大时，沟通成本、管理成本显著增加。当出现 bug 时，可能引起 bug 的原因组合越来越多，导致分析、定位和修复的成本增加；并且在对全局功能缺乏深度理解的情况下，容易在修复 bug 时引入新的 bug。

4. **持续交付周期长**

   构建和部署时间会随着功能的增多而增加，任何细微的修改都会触发部署流水线。新人培养周期长：新成员了解背景、熟悉业务和配置环境的时间越来越长。

5. **技术选型成本高**

   单块架构倾向于采用统一的技术平台或方案来解决所有问题，会形成长期的依赖，如果后续想引入新的技术或框架，成本和风险都很大，因为这个应用必须被彻底重写。

6. **可扩展性差**

   随着功能的增加，垂直扩展的成本将会越来越大；而对于水平扩展而言，因为所有代码都运行在同一个进程，没办法做到针对应用程序的部分功能做独立的扩展。

## 与单体式服务架构对比

|            |      传统单体架构      |                   微服务架构                   |
| :--------: | :--------------------: | :--------------------------------------------: |
| 新功能开发 |         时间长         |                   易开发实现                   |
|    部署    |    不经常且容易部署    |               经常发布，部署复杂               |
|  架构设计  |   初期技术选型难度大   |                 设计逻辑难度大                 |
|   隔离性   |     故障影响范围大     |                 故障影响范围小                 |
|  系统性能  |  相对时间快，吞吐量小  |              相对时间慢，吞吐量大              |
|  系统运维  |      运维难度简单      |                  运维难度复杂                  |
|  新人上手  | 学习曲线大（应用逻辑） |             学习曲线大（架构逻辑）             |
|    技术    |     技术单一且封闭     |                 技术多样易开发                 |
| 测试和差错 |          简单          | 复杂（每个服务都要进行单独测试，还需集群测试） |
| 系统扩展性 |        扩展性差        |                    扩展性好                    |
|  系统管理  |     重点在开发成本     |             重点在于服务治理和调度             |

## 微服务设计原则

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202438093-973893071.png)

- 单一职责原则

意思是每个微服务只需要实现自己的业务逻辑就可以了，比如订单管理模块，它只需要处理订单的业务逻辑就可以了，其它的不必考虑。

- 服务自治原则

意思是每个微服务从开发、测试、运维等都是独立的，包括存储的数据库也都是独立的，自己就有一套完整的流程，我们完全可以把它当成一个项目来对待。不必依赖于其它模块。

- 轻量级通信原则

首先是通信的语言非常的轻量，第二，该通信方式需要是跨语言、跨平台的，之所以要跨平台、跨语言就是为了让每个微服务都有足够的独立性，可以不受技术的钳制。

- 接口明确原则

由于微服务之间可能存在着调用关系，为了尽量避免以后由于某个微服务的接口变化而导致其它微服务都做调整，在设计之初就要考虑到所有情况，让接口尽量做的更通用，更灵活，从而尽量避免其它模块也做调整。

## 微服务优缺点分析

### 微服务架构有哪些好处？

1. **单一职责**

   微服务架构中的每个服务，都是具有业务逻辑的，符合高内聚、低耦合原则以及单一职责原则的单元，不同的服务通过“管道”的方式灵活组合，从而构建出庞大的系统。

2. **轻量级通信**

   服务之间通过轻量级的通信机制实现互通互联，而所谓的轻量级，通常指语言无关、平台无关的交互方式。对于轻量级通信的格式而言，我们熟悉的 XML 和 JSON，它们是语言无关、平台无关的；

   对于通信的协议而言，通常基于 HTTP，能让服务间的通信变得标准化、无状态化。使用轻量级通信机制，可以让团队选择更适合的语言、工具或者平台来开发服务本身。

3. **服务相对小，独立部署和扩展**

   微服务架构的一个好处是：每个服务都比较小，卡法这更容易理解服务中的代码。较小规模的代码不会拖慢IDE等开发工具，提升效率，且服务的启动速度也比大型单体应用快得多，这在调试，部署等环节都能节省大量时间。

   在微服务架构中，每个服务都是独立的业务单元，与其他服务高度解耦，只需要改变当前服务本身，就可以完成独立的开发、测试和部署。

4. **更易实验和采用新技术**

   微服务架构可以消除对某项技术栈的长期依赖。原则上，当开发一个新的服务时，开发者可以自由选择适用于这个服务的任何语言和框架。当然，很多公司对此往往有各种限制和规范，但重要的是团队有了选择的权利，而不是被之前选定的技术绑架。
   更进一步，因为服务都相对比较小，使用更好的编程语言和技术来重写一项服务变得有可能。这也意味着，如果对一项新技术的尝试以失败而告终，我们可以直接丢弃这部分工作而不至于给整个应用带来失败的风险。这跟单体架构是完全不同的，单体架构之下的技术选型会严重限制后期新技术的尝试。

5. **更好的容错性**

   微服务架构也可以实现更好的故障隔离。例如，某个服务中的内存泄漏不会影响其他服务。其他服务仍旧可以正常地响应请求。相比之下，单体架构中的一个故障组件往往会拖垮整个系统。

### 微服务有何不足？

1. **服务拆分和定义较困难**

   采用微服务架构首当其冲的问题，就是根本没有一个具体的、良好定义的算法可以完成服务的拆分工作。与软件开发一样，服务的拆分和定义更像是一门艺术。更糟糕的是，如果对系统的服务拆分出现了偏差，你很有可能会构建出一个分布式的单体应用:一个包含了一大堆互相之间紧耦合的服务，却又必须部署在一起的所谓分布式系统。这将会把单体架构和微服务架构两者的弊端集于一身。

2. **运维要求比较高**

   对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。

3. **接口成本高**

   比如我们的前面的电商项目每个模块做成微服务的话，用户微服务是要被订单微服务和购物车微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。

4. **重复劳动**

   对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用，但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服务上都建这么一个工具类，从而导致代码的重复。

5. **业务不好分离**

   程序员的业务理解程度

|            优点            |              缺点              |
| :------------------------: | :----------------------------: |
| 服务相对小，独立部署和扩展 |      服务拆分和定义较困难      |
|          职责单一          |           运维成本高           |
|         轻量级通信         |           接口成本高           |
|    更易实验和采用新技术    |           重复性劳动           |
|        更好的容错性        | 业务分离困难（产生了技术中台） |

## 微服务的监控 - 发现故障征兆

​		在高并发分布式的场景下，故障经常是突然间就雪崩式爆发。所以必须建立完善的监控体系，尽可能发现故障的征兆。

​		微服务架构中组件繁多，各个组件所需要监控的指标不同。比如Redis缓存一般监控占用内存值、网络流量，数据库监控连接数、磁盘空间，业务服务监控并发数、响应延迟、错误率等。因此如果做一个大而全的监控系统来监控各个组件是不大现实的，而且扩展性会很差。一般的做法是让各个组件提供报告自己当前状态的接口（metrics接口），这个接口输出的数据格式应该是一致的。然后部署一个指标采集器组件，定时从这些接口获取并保持组件状态，同时提供查询服务。最后还需要一个UI，从指标采集器查询各项指标，绘制监控界面或者根据阈值发出告警。

​		大部分组件都不需要自己动手开发，网络上有开源组件。如下图的RedisExporter和MySQLExporter，这两个组件分别提供了Redis缓存和MySQL数据库的指标接口。微服务则根据各个服务的业务逻辑实现自定义的指标接口。采用Prometheus作为指标采集器，Grafana配置监控界面和邮件告警。这样一套微服务监控系统就搭建起来了：

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202505346-382977682.jpg)

## 定位问题 - 链路跟踪

​		在微服务架构下，一个用户的请求往往涉及多个内部服务调用。为了方便定位问题，需要能够记录每个用户请求时，微服务内部产生了多少服务调用，及其调用关系。这个叫做链路跟踪。

我们用一个Istio文档里的链路跟踪例子来看看效果：

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202716477-230389284.png)

> 图片来自[Istio文档](https://istio.io/zh/docs/tasks/telemetry/distributed-tracing/zipkin/)

​		从图中可以看到，这是一个用户访问productpage页面的请求。在请求过程中，productpage服务顺序调用了details和reviews服务的接口。而reviews服务在响应过程中又调用了ratings的接口。整个链路跟踪的记录是一棵树：

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202529745-761706189.png)

要实现链路跟踪，每次服务调用会在HTTP的HEADERS中记录至少记录四项数据：

- traceId：traceId标识一个用户请求的调用链路。具有相同traceId的调用属于同一条链路。
- spanId：标识一次服务调用的ID，即链路跟踪的节点ID。
- parentId：父节点的spanId。
- requestTime & responseTime：请求时间和响应时间。

另外，还需要调用日志收集与存储的组件，以及展示链路调用的UI组件。

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202538814-1365520338.png)

以上只是一个极简的说明，关于链路跟踪的理论依据可详见Google的[Dapper](http://bigbully.github.io/Dapper-translation/)

​		了解了理论基础后，我们选用了Dapper的一个开源实现Zipkin。设置了HTTP请求的拦截器，在每次HTTP请求时生成这些数据注入到HEADERS，同时异步发送调用日志到Zipkin的日志收集器中。这里额外提一下，HTTP请求的拦截器，可以在微服务的代码中实现，也可以使用一个网络代理组件来实现（不过这样子每个微服务都需要加一层代理）。

链路跟踪只能定位到哪个服务出现问题，不能提供具体的错误信息。查找具体的错误信息的能力则需要由日志分析组件来提供。

## 分析问题 - 日志分析

​		日志分析组件应该在微服务兴起之前就被广泛使用了。即使单体应用架构，当访问数变大、或服务器规模增多时，日志文件的大小会膨胀到难以用文本编辑器进行访问，更糟的是它们分散在多台服务器上面。排查一个问题，需要登录到各台服务器去获取日志文件，一个一个地查找（而且打开、查找都很慢）想要的日志信息。

​		因此，在应用规模变大时，我们需要一个日志的“**搜索引擎**”。以便于能准确的找到想要的日志。另外，数据源一侧还需要收集日志的组件和展示结果的UI组件：

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202551377-1925565690.png)

我们都知道大名鼎鼎的ELK日志分析组件。ELK是Elasticsearch、Logstash和Kibana三个组件的缩写。

- Elasticsearch：搜索引擎，同时也是日志的存储。
- Logstash：日志采集器，它接收日志输入，对日志进行一些预处理，然后输出到Elasticsearch。
- Kibana：UI组件，通过Elasticsearch的API查找数据并展示给用户。

​		最后还有一个小问题是如何将日志发送到Logstash。一种方案是在日志输出的时候直接调用Logstash接口将日志发送过去。这样一来又要修改代码……于是我们选用了另一种方案：日志仍然输出到文件，每个服务里再部署个Agent扫描日志文件然后输出给Logstash。

## 网关 - 权限控制，服务治理

​		拆分成微服务后，出现大量的服务，大量的接口，使得整个调用关系乱糟糟的。经常在开发过程中，写着写着，忽然想不起某个数据应该调用哪个服务。或者写歪了，调用了不该调用的服务，本来一个只读的功能结果修改了数据……

​		为了应对这些情况，微服务的调用需要一个把关的东西，也就是网关。在调用者和被调用者中间加一层网关，每次调用时进行权限校验。另外，网关也可以作为一个提供服务接口文档的平台。

​		使用网关有一个问题就是要决定在多大粒度上使用：最粗粒度的方案是整个微服务一个网关，微服务外部通过网关访问微服务，微服务内部则直接调用；最细粒度则是所有调用，不管是微服务内部调用或者来自外部的调用，都必须通过网关。折中的方案是按照业务领域将微服务分成几个区，区内直接调用，区间通过网关调用。

由于当前架构的服务数量还不算特别多，我们采用的最粗粒度的方案：

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202601454-2140609469.png)

## 服务注册于发现 - 动态扩容

​		前面的组件，都是旨在降低故障发生的可能性。然而故障总是会发生的，所以另一个需要研究的是如何降低故障产生的影响。

​		最粗暴的（也是最常用的）故障处理策略就是冗余。一般来说，一个服务都会部署多个实例，这样一来能够分担压力提高性能，二来即使一个实例挂了其他实例还能响应。

​		冗余的一个问题是使用几个冗余？这个问题在时间轴上并没有一个切确的答案。根据服务功能、时间段的不同，需要不同数量的实例。比如在平日里，可能4个实例已经够用；而在促销活动时，流量大增，可能需要40个实例。因此冗余数量并不是一个固定的值，而是根据需要实时调整的。

​		一般来说新增实例的操作为：

1. 部署新实例
2. 将新实例注册到负载均衡或DNS上

​		操作只有两步，但如果注册到负载均衡或DNS的操作为人工操作的话，那事情就不简单了。想想新增40个实例后，要手工输入40个IP的感觉不言而喻......

​		解决这个问题的方案是服务自动注册与发现。首先，需要部署一个服务发现服务，它提供所有已注册服务的地址信息的服务。DNS也算是一种服务发现服务。然后各个应用服务在启动时自动将自己注册到服务发现服务上。并且应用服务启动后会实时（定期）从服务发现服务同步各个应用服务的地址列表到本地。服务发现服务也会定期检查应用服务的健康状态，去掉不健康的实例地址。这样新增实例时只需要部署新实例，实例下线时直接关停服务即可，服务发现会自动检查服务实例的增减。

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202612906-90547951.png)

​		服务发现还会跟客户端负载均衡配合使用。由于应用服务已经同步服务地址列表在本地了，所以访问微服务时，可以自己决定负载策略。甚至可以在服务注册时加入一些元数据（服务版本等信息），客户端负载则根据这些元数据进行流量控制，实现A/B测试、蓝绿发布等功能。

服务发现有很多组件可以选择，比如说Zookeeper 、Eureka、Consul、Etcd等。

## 熔断、服务降级、限流

### 熔断

​		当一个服务因为各种原因停止响应时，调用方通常会等待一段时间，然后超时或者收到错误返回。如果调用链路比较长，可能会导致请求堆积，整条链路占用大量资源一直在等待下游响应。所以当多次访问一个服务失败时，应熔断，标记该服务已停止工作，直接返回错误。直至该服务恢复正常后再重新建立连接。

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202623628-671154877.png)

> 图片来自《[微服务设计](https://book.douban.com/subject/26772677/)》

### 服务降级

​		当下游服务停止工作后，如果该服务并非核心业务，则上游服务应该降级，以保证核心业务不中断。比如架构中下单界面有一个推荐商品凑单的功能，当推荐模块挂了后，下单功能不能一起挂掉，只需要暂时关闭推荐功能即可。

### 限流

​		一个服务挂掉后，上游服务或者用户一般会习惯性地重试访问。这导致一旦服务恢复正常，很可能因为瞬间网络流量过大又立刻挂掉，在棺材里重复着仰卧起坐。因此服务需要能够自我保护——限流。限流策略有很多，最简单的比如当单位时间内请求数过多时，丢弃多余的请求。另外，也可以考虑分区限流。仅拒绝来自产生大量请求的服务的请求。例如商品服务和订单服务都需要访问促销服务，商品服务由于代码问题发起了大量请求，促销服务则只限制来自商品服务的请求，来自订单服务的请求则正常响应。

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822202634424-2040470592.png)

## 测试

微服务架构下，测试分为三个层次：

1. 端到端测试：覆盖整个系统，一般在用户界面机型测试。
2. 服务测试：针对服务接口进行测试。
3. 单元测试：针对代码单元进行测试。

​		三种测试从上到下实施的容易程度递增，但是测试效果递减。端到端测试最费时费力，但是通过测试后我们对系统最有信心。单元测试最容易实施，效率也最高，但是测试后不能保证整个系统没有问题。

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822210300615-890524557.png)

​		由于端到端测试实施难度较大，一般只对核心功能做端到端测试。一旦端到端测试失败，则需要将其分解到单元测试：则分析失败原因，然后编写单元测试来重现这个问题，这样未来我们便可以更快地捕获同样的错误。

服务测试的难度在于服务会经常依赖一些其他服务。这个问题可以通过Mock Server解决：

![img](https://img2018.cnblogs.com/blog/576869/201908/576869-20190822210316819-714945851.png)

单元测试大家都很熟悉了。我们一般会编写大量的单元测试（包括回归测试）尽量覆盖所有代码。

# 服务网格service mesh

## 定义

​		Service Mesh 作为下一代微服务技术的代名词，初出茅庐却深得人心一鸣惊人，大有一统微服务时代的趋势。那么到底什么是 Service Mesh？

​		**一言以蔽之：Service Mesh 是微服务时代的 TCP/IP 协议**

​		有了这样一个感性的初步认知，我们再来看到底什么是Service Mesh

​		**服务网格**是用于**控制和监控**微服务应用程序中的内部服务到服务流量的软件基础结构层。它通常采取与应用程序代码一起部署，作为网络代理的 **"数据平面"** 和与这些代理交互的 **"控制平面"** 的形式。在此模型中，服务网格对于开发人员 (服务所有者) 是透明的， 而运维人员 (平台工程师) 则被授予一套新的工具，以确保可靠性、安全性和可见性。

​		一般介绍 service mesh 的文章都会从网络层的又一个抽象说起，把 service mesh 看做建立在 TCP 层之上的微服务层。我们换个思路，从 service mesh 的技术根基——网络代理来分析。

### 网络代理

​		说起网络代理，我们会想到翻墙，如果对软件架构比较熟悉的会想到 Nginx 等反向代理软件。其实网络代理的范围比较广，可以肯定的说，有网络访问的地方就会有代理的存在。

Wikipedia 对代理的定义如下：

In computer networks, a proxy server is a server (a computer system or an application) that acts as an intermediary for requests from clients seeking resources from other servers.

```
翻译：在计算机网络中，代理服务器是一种服务器（计算机系统或应用程序），它充当客户端请求从其他服务器寻求资源的中介。
```

NOTE：代理可以是嵌套的，也就是说通信双方 A、B 中间可以多多层代理，而这些代理的存在有可能对 A、B 是透明的。

​		简单来说，网络代理可以简单类比成现实生活中的中介，本来需要通信的双方因为各种原因在中间再加上一道关卡。本来双方就能完成的通信，为何非要多此一举呢？那是因为代理可以为整个通信带来更多的功能，比如：

**拦截**：代理可以选择性拦截传输的网络流量，比如一些公司限制员工在上班的时候不能访问某些游戏或者电商网站，再比如把我们和世界隔离开来的 GFW，还有在数据中心中拒绝恶意访问的网关

**统计**：既然所有的流量都经过代理，那么代理也可以用来统计网络中的数据信息，比如了解哪些人在访问哪些网站，通信的应答延迟等

**缓存**：如果通信双方比较”远“，访问比较慢，那么代理可以把最近访问的数据缓存在本地，后面的访问不用访问后端来做到加速。CDN 就是这个功能的典型场景

**分发**：如果某个通信方有多个服务器后端，代理可以根据某些规则来选择如何把流量发送给多个服务器，也就是我们常说的负载均衡功能。比如著名的 Nginx 软件

**跳板**：如果 A、B 双方因为某些原因不能直接访问，而代理可以和双方通信，那么通过代理，双方可以绕过原来的限制进行通信。这应该广大中国网民比较熟悉的场景

**注入**：既然代理可以看到流量，那么它也可以修改网络流量，可以自动在收到的流量中添加一些数据，比如有些宽带提供商的弹窗广告

### 微服务架构中的代理

​		而 service mesh 可以看做是传统代理的升级版，用来解决现在微服务框架中出现的问题，可以把 service mesh 看做是分布式的微服务代理。

​		在传统模式下，代理一般是集中式的单独的服务器，所有的请求都要先通过代理，然后再流入转发到实际的后端。

​		而在 service mesh 中，代理变成了分布式的，它常驻在了应用的身边（最常见的就是 **kubernetes sidecar** 模式，每一个应用的 pod 中都运行着一个代理，负责流量相关的事情）。这样的话，应用所有的流量都被代理接管，那么这个代理就能做到上面提到的所有可能的事情，从而带来无限的想象力。

​		此外，原来的代理都是基于网络流量的，一般都是工作在 IP 或者 TCP 层，很少关心具体的应用逻辑。但是 service mesh 中，代理会知道整个集群的所有应用信息，并且额外添加了热更新、注入服务发现、降级熔断、认证授权、超时重试、日志监控等功能，让这些通用的功能不必每个应用都自己实现，放在代理中即可。换句话说，service mesh 中的代理对微服务中的应用做了定制化的改进！

​		就这样，借着微服务和容器化的东风，传统的代理摇身一变，成了如今炙手可热的 service mesh。应用微服务之后，每个单独的微服务都会有很多副本，而且可能会有多个版本，这么多微服务之间的相互调用和管理非常复杂，但是有了 service mesh，我们可以把这块内容统一在代理层。

​		有了看起来四通八达的分布式代理，我们还需要对这些代理进行统一的管理。手动更新每个代理的配置，对代理进行升级或者维护是个不可持续的事情，在前面的基础上，在加上一个控制中心，一个完整的 service mesh 就成了。管理员只需要根据控制中心的 API 来配置整个集群的应用流量、安全规则即可，代理会自动和控制中心打交道根据用户的期望改变自己的行为。

> NOTE：所以你也可以理解 service mesh 中的代理会抢了 Nginx 的生意，这也是为什么Nginx 也要开始做 NginMesh 的原因。

## 服务网格的历史演进

**时代0**：开发人员想象中，不同服务间通信的方式，抽象表示如下：

![img](https://pic4.zhimg.com/80/v2-2a182cea5ab0f7d625776a9446cd596b_720w.jpg)



**时代1：原始通信时代**

​		然而现实远比想象的复杂，在实际情况中，通信需要底层能够传输字节码和电子信号的物理层来完成，在TCP协议出现之前，服务需要自己处理网络通信所面临的丢包、乱序、重试等一系列流控问题，因此服务实现中，除了业务逻辑外，还夹杂着对网络传输问题的处理逻辑。

![img](https://pic4.zhimg.com/80/v2-1443e6bebd93d5e6bb1c18197676d29b_720w.jpg)



**时代2：TCP时代**

​		为了避免每个服务都需要自己实现一套相似的网络传输处理逻辑，TCP协议出现了，它解决了网络传输中通用的流量控制问题，将技术栈下移，从服务的实现中抽离出来，成为操作系统网络层的一部分。

![img](https://pic2.zhimg.com/80/v2-9e6c4c6b4229b947b4efdf63de86f695_720w.jpg)



**时代3：第一代微服务**

​		在TCP出现之后，机器之间的网络通信不再是一个难题，以GFS/BigTable/MapReduce为代表的分布式系统得以蓬勃发展。这时，分布式系统特有的通信语义又出现了，如熔断策略、负载均衡、服务发现、认证和授权、quota限制、trace和监控等等，于是服务根据业务需求来实现一部分所需的通信语义。

![img](https://pic1.zhimg.com/80/v2-b31cc447637c71b887ac80c0bfa680d4_720w.jpg)



**时代4：第二代微服务**

​		为了避免每个服务都需要自己实现一套分布式系统通信的语义功能，随着技术的发展，一些面向微服务架构的开发框架出现了，如Twitter的[Finagle](https://link.zhihu.com/?target=https%3A//finagle.github.io/)、Facebook的[Proxygen](https://link.zhihu.com/?target=https%3A//code.facebook.com/posts/1503205539947302)以及Spring Cloud等等，这些框架实现了分布式系统通信需要的各种通用语义功能：如负载均衡和服务发现等，因此一定程度上屏蔽了这些通信细节，使得开发人员使用较少的框架代码就能开发出健壮的分布式系统。

![img](https://pic1.zhimg.com/80/v2-9382bf9facb290eceed01d998ac2ef44_720w.jpg)



**时代5：第一代Service Mesh**

第二代微服务模式看似完美，但开发人员很快又发现，它也存在一些本质问题：

- 其一，虽然框架本身屏蔽了分布式系统通信的一些通用功能实现细节，但开发者却要花更多精力去掌握和管理复杂的框架本身，在实际应用中，去追踪和解决框架出现的问题也绝非易事；
- 其二，开发框架通常只支持**一种或几种特定的语言**，回过头来看文章最开始对微服务的定义，一个重要的特性就是**语言无关**，但那些没有框架支持的语言编写的服务，很难融入面向微服务的架构体系，想因地制宜的用多种语言实现架构体系中的不同模块也很难做到；
- 其三，框架以lib库的形式和服务联编，复杂项目依赖时的库版本兼容问题非常棘手，同时，框架库的升级也无法对服务透明，服务会因为和业务无关的lib库升级而被迫升级；

因此以Linkerd，Envoy，NginxMesh为代表的代理模式（Sidecar模式）应运而生，这就是第一代Service Mesh，它将分布式服务的通信抽象为单独一层，在这一层中实现负载均衡、服务发现、认证授权、监控追踪、流量控制等分布式系统所需要的功能，作为一个和服务对等的代理服务，和服务部署在一起，接管服务的流量，通过代理之间的通信间接完成服务之间的通信请求，这样上边所说的三个问题也迎刃而解。

![img](https://pic2.zhimg.com/80/v2-e5660d35a311467c3323f10ebf2fb9a5_720w.jpg)

如果我们从一个全局视角来看，就会得到如下部署图：

![img](https://pic4.zhimg.com/80/v2-8a9cc161a34d97f36ead06d0abc5b1fb_720w.jpg)

如果我们暂时略去服务，只看Service Mesh的单机组件组成的网络：

![img](https://pic2.zhimg.com/80/v2-ee0bde35f9ec79bf38feda98550b8f71_720w.jpg)

相信现在，我们已经理解何所谓Service Mesh，也就是服务网格了。它看起来确实就像是一个由若干服务代理所组成的错综复杂的网格。

**时代6：第二代Service Mesh**

​		第一代Service Mesh由一系列独立运行的单机代理服务构成，为了提供统一的上层运维入口，演化出了集中式的控制面板，所有的单机代理组件通过和控制面板交互进行网络拓扑策略的更新和单机数据的汇报。这就是以Istio为代表的第二代Service Mesh。

![img](https://pic3.zhimg.com/80/v2-546ed82e25d83a2cb404b0a3f526f9c6_720w.jpg)

只看单机代理组件(数据面板)和控制面板的Service Mesh全局部署视图如下：

![img](https://pic4.zhimg.com/80/v2-8686840abd3de29e5cb6e8dcfa78182f_720w.jpg)



​		至此，见证了6个时代的变迁，我们应该清楚了Service Mesh技术到底是什么，以及是如何一步步演化到今天这样一个形态。

现在，我们再回过头来看Buoyant的CEO William Morgan，也就是Service Mesh这个词的发明人，对Service Mesh的定义：

> 服务网格是一个**基础设施层**，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证**请求在这些拓扑中可靠地穿梭**。在实际应用当中，服务网格通常是由一系列轻量级的**网络代理**组成的，它们与应用程序部署在一起，但**对应用程序透明**。

这个定义中，有四个关键词：

**基础设施层**请求在这些拓扑中可靠穿梭：这两个词加起来描述了Service Mesh的定位和功能，是不是似曾相识？没错，你一定想到了TCP

**网络代理**：这描述了Service Mesh的实现形态

**对应用透明**：这描述了Service Mesh的关键特点，正是由于这个特点，Service Mesh能够解决以Spring Cloud为代表的第二代微服务框架所面临的三个本质问题

总结一下，Service Mesh具有如下优点：

- 屏蔽分布式系统通信的复杂性(负载均衡、服务发现、认证授权、监控追踪、流量控制等等)，服务只用关注业务逻辑
- 真正的语言无关，服务可以用任何语言编写，只需和Service Mesh通信即可
- 对应用透明，Service Mesh组件可以单独升级

当然，Service Mesh目前也面临一些挑战：

- Service Mesh组件以代理模式计算并转发请求，一定程度上会降低通信系统性能，并增加系统资源开销
- Service Mesh组件接管了网络流量，因此服务的整体稳定性依赖于Service Mesh，同时额外引入的大量Service Mesh服务实例的运维和管理也是一个挑战

## 服务网格与云原生的关系

### 服务网格 —— 容器编排大战后的产物



![img](https://pic3.zhimg.com/80/v2-d44597bbbfff3849a76048291d052cba_720w.jpg)

​		关于服务网格的起源已经无需多言。2017 年 Kubernetes 获得了容器大战的胜利，微服务的理念已经深入人心，容器化的趋势可谓势不可挡。Kubernetes 架构趋向成熟，慢慢变得无聊，以 Linkerd、Istio 为代表的服务网格技术进入了 CNCF （Cloud Native Computing Foundation）定义的云原生关键技术视野中。

​		服务网格将微服务中的通用的功能给下沉到了基础设施层，让开发者可以更加专注于业务逻辑，从而加快服务交付，这与整个云原生的理念的一致的。你不需要再在应用中集成笨重的 SDK，为不同语言开发和维护 SDK，应用部署完后，使用服务网格进行 Day 2 操作即可。

​		Kubernetes 设计之初就是按照云原生的理念设计的，云原生中有个重要概念就是微服务的架构设计，当将单体应用拆分微服务后， 随着服务数量的增多，如何微服务进行管理以保证服务的 SLA 呢？为了从架构层面上解决这个问题，解放程序员的创造性，避免繁琐的服务发现、监控、分布式追踪等事务，服务网格应运而生。



![img](https://pic1.zhimg.com/80/v2-d4ea510dd23e1802c2353fd7e9e165f4_720w.jpg)



来源：*[https://developers.redhat.com/blog/2016/12/09/spring-cloud-for-microservices-compared-to-kubernetes](https://link.zhihu.com/?target=https%3A//developers.redhat.com/blog/2016/12/09/spring-cloud-for-microservices-compared-to-kubernetes)*

​		服务网格被誉为下一代微服务，从右面这幅图里我们可以看到微服务的一些关注点，这些关注点很多与 Kubernetes 的功能是重合的，既然这些作为平台级的功能 Kubernetes 已经提供了，为什么还要使用服务网格呢？其实 Kubernetes 关注的还是应用的生命周期，它管理的对象是**资源和部署**，对于服务的管控力度很小。而服务网格正好弥补了这个缺陷。服务网格可以**连接、控制、观察和保护微服务**。

### Kubernetes vs xDS vs Istio



![img](https://pic3.zhimg.com/80/v2-353e7d4b5ecff6627ddd6c160ae2b862_720w.jpg)



​		这幅图展示的是 Kubernetes 和 Istio 的分层架构图。从图中我们可以看到 kube-proxy 的设置是全局的，无法对每个服务进行细粒度的控制，Kubernetes 可以做的只有拓扑感知路由、将流量就近路由，为 Pod 设置进出站的网络策略。

​		而服务网格通过 sidecar proxy 的方式将 Kubernetes 中的流量控制从服务层中抽离出来，为每个 Pod 中注入代理，并通过一个控制平面来操控这些分布式代理。这样可以实现更大的弹性。

​		Kube-proxy 实现了一个 Kubernetes 服务的多个 pod 实例之间的流量负载均衡，但如何对这些服务之间的流量进行精细化控制–比如将流量按百分比划分给不同的应用版本（这些应用版本都是同一个服务的一部分，但在不同的部署上），或者做金丝雀发布（灰度发布）和蓝绿发布？

Kubernetes 社区给出了一个使用 Deployment 做金丝雀发布的方法，本质上是通过修改 pod 的标签来给部署的服务分配不同的 pod。

![img](https://pic2.zhimg.com/80/v2-546312d8c193026cc0ada01f2f299ce5_720w.jpg)

​		目前在中国最流行的服务网格开源实现是 Istio，也有很多公司对 Istio 进行了二次开发，比如蚂蚁、网易、腾讯等，其实 Istio 是在 Envoy 的基础上开发的，从它开源的第一天起就默认使用了 Envoy 作为它的分布式代理。Envoy 开创性的创造了 xDS 协议，用于分布式网关配置，大大简化了大规模分布式网络的配置。2019 年蚂蚁开源的 MOSN 同样支持了 xDS。Envoy 还是 CNCF 中最早毕业的项目之一，经过大规模的生产应用考验。可以说 Istio 的诞生已经有了很好的基础。

下表是 Kubernetes、xDS、Istio 三者之间的资源抽象对比。

![img](https://pic2.zhimg.com/80/v2-879ca36e7c0dddbf048075025ff381f5_720w.jpg)

​		kube-proxy 组件、xDS 和 Istio 对流量管理的抽象后，现在我们仅从流量管理的角度来看看这三个组件 / 协议的比较。请注意，三者并不完全等同。Kubernetes 更加注重的是应用层面的流量管理，xDS 是更加抽象的协议层面的配置下发，而 Istio 是服务层面的配置。

### 服务网格 —— 云原生网络基础设施

​		在列举过以上 Kubernetes 和服务网格的对比后，我们可以看出服务网格在云原生应用架构中的地位。那就是构建一个云原生网络基础设施，具体来说就是：

- 流量管理：控制服务间的流量和 API 调用流，使调用更可靠，增强不同环境下的网络鲁棒性。
- 可观测性：了解服务之间的依赖关系和它们之间的性质和流量，提供快速识别定位问题的能力。
- 策略实施：通过配置网格而不是以改变代码的方式来控制服务之间的访问策略。
- 服务识别与安全：提供在网格里的服务可识别性和安全性保护。

### 社区关于 Istio 和服务网格的争论

​		然而构建基础设施，可谓牵一发而动全身。理想很丰满，现实很骨感。关于服务网格和 Istio，在社区中也不乏争论。我们来看看有这些争论主要有哪些。

这里列举了我在社区中观察到的关于 Istio 和服务网格最常见的几个问题。

1. 有人在生产使用 Istio 吗？
2. 为 pod 注入 sidecar 后带来的大量资源消耗，影响应用性能？
3. Istio 支持的协议有限，不易扩展？
4. Istio 太过复杂，老的服务迁移成本太高，业界经验太少，学习曲线陡峭？

### Istio 架构稳定，生产可用，生态渐起



![img](https://pic3.zhimg.com/80/v2-c8cfa3c8049ddb488c489b94184c505a_720w.jpg)



​		首先我们来看下 Istio 的发布时间表，1.12 版本在上周刚刚发布，这里列举了从它开源到 1.8 版本发布的时间表。2018 年可以说是服务网格爆发之年，Tetrate 也在这一年成立。自 1.5 版本起 Istio 正式确立了当前的架构。Istio 社区也也举办了丰富多彩的活动，2021 年 3 月首届 IstioCon 召开，7 月 Istio Meetup China 在北京举行，2022 年 1 月，Service Mesh Summit 2022 也将在上海举行。

​		Istio 有着庞大的社区以及[供应商和用户群体](https://link.zhihu.com/?target=https%3A//istio.io/latest/about/case-studies/)。目前主流公有云全都支持了 Istio 服务网格，如阿里云、华为云、腾讯云、网易云等，Istio 的官网上也列举了几十个社区用户，云原生社区 Istio SIG 还陆续举办了八场 [Istio 大咖说](https://link.zhihu.com/?target=https%3A//cloudnative.to/sig-istio/big-talk/overview.html)，百度、腾讯、网易、小红书、小电科技都来分享过他们的 Istio 实践。

还有很多企业基于 Istio 做了二次开发或者适配或者为其开发插件，可以说是 Istio 架构已稳定，生产可用，生态正在萌芽中。

### 服务网格对应用性能的影响

​		服务网格为了做到对应用程序透明，默认采用了 iptables 流量劫持的方式，当服务数量大的时候会有大量的 iptables 规则，影响网络性能，你可以使用 [eBPF](https://link.zhihu.com/?target=https%3A//cloudnative.to/blog/how-ebpf-streamlines-the-service-mesh/) 这样的技术来提供应用性能，但是该技术对操作系统内核的版本要求比较高，很少有企业能够达到。



![img](https://pic2.zhimg.com/80/v2-0f58d814102c55aed614a33550e89f59_720w.jpg)



来源：[https://cloudnative.to/blog/istio-dns-proxy/](https://link.zhihu.com/?target=https%3A//cloudnative.to/blog/istio-dns-proxy/)

还有一种方式，也是[小红书使用的方式](https://link.zhihu.com/?target=https%3A//cloudnative.to/sig-istio/big-talk/ep08.html)，那就是利用 Istio 1.8 中引入的智能 DNS 代理功能。首先使用 ServiceEntry 定义服务，让所有服务属于一个 VIP 范围，再利用 Istio 的智能 DNS 代理功能，让 sidecar 只拦截 VIP 网段的流量，这样可以减少 iptables 规则，从而提高性能。如果想深入了解这个做法的细节，可以去浏览 [Istio 大咖说第八期的分享视频](https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV12b4y187ae/)。

Istio 在初期是将整个网格内的所有服务的路由信息全量下发到所有的 proxy sidecar 中，会导致 sidecar 占用大量资源，后来 Istio 引入了 [Sidecar 资源](https://link.zhihu.com/?target=https%3A//istio.io/latest/docs/reference/config/networking/sidecar/)来精细化控制需要下发的代理配置范围，另外还有企业自己开发了配置懒加载功能，例如腾讯云开源的 [Aeraki](https://link.zhihu.com/?target=https%3A//github.com/aeraki-framework/aeraki)、网易开源的 [Slime](https://link.zhihu.com/?target=https%3A//github.com/slime-io/slime) 都可以实现配置懒加载。我们会在 Istio 开源生态中介绍这两个开源项目。

最后是一个涉及到 Sidecar proxy 运维的问题，如何在保证流量不断的情况下，升级所有 Envoy 代理，这个阿里开源的 [OpenKruise](https://link.zhihu.com/?target=https%3A//github.com/openkruise/kruise) 中的 [SidecarSet](https://link.zhihu.com/?target=https%3A//xie.infoq.cn/article/23ae6d3f0d0260b4797a708a0) 资源已经给出了解决方案。

另外 Sidecar 的引入带来的资源消耗以及网络延迟也是在合理的范围内，大家可以参考 Istio 官方博客上的 [Service Mesh 基准性能测试](https://link.zhihu.com/?target=https%3A//istio.io/latest/zh/blog/2019/performance-best-practices/)。

## Sidecar 是什么

### Sidecar定义

​		sidecar抽离了本该属于应用程序的功能而将其拆分成单独的进程，这个进程可以被理解为Sidecar。

​		在微服务体系内，因为集成在应用内的微服务功能剥离到了sidecar内，该模式允许我们向应用**无侵入式**地添加多种功能，避免了为满足第三方组件需求而向应用添加额外的配置代码，**所以Sidecar所包含的功能有：负载均衡，服务发现，服务调用，应用认证，限速等功能**。

​		Sidecar概念类似nginx，但是相比增加了很多功能，比如服务发现，流量管理等。Sidecar可以解决的问题是，降低微服务架构的复杂度，将与通信相关的服务抽离出来，完善微服务之间的治理问题。

![](http://myimg.go2flare.xyz/img/image-20220221034141944.png)

### Sidecar的探索之路

很多公司借鉴了Proxy模式，推出了Sidecar的产品
如：

- Netflix的Prana
- 蚂蚁金服的SofaMesh
- 而Twitter发布了第一款service mesh项目：linkerd

## Linkerd

```
2016年1月，离开Twitter的基础设施工程师打造的一个服务网格项目，第一个Service Mesh项目由此诞生，解决通用性。
Linkerd很好地结合了Kubernetes所提供的功能，以此为基础，在每个Kubernetes Node上都部署运行一个Linkerd实例，用代理的方式将加入Mesh的Pod通信转接给Linkerd，这样Linkerd就能在通信链路中完成对通信的控制和监控。
```

### 设计思想

![image-20220221034051962](http://myimg.go2flare.xyz/img/image-20220221034051962.png)

Linkerd的思想跟sidecar很类似，目标也是屏蔽网络通信细节
Linkerd除了完成对Service Mesh的命名，以及Service Mesh各主要功能的落地，还有以下重要创举:

- 无须侵入工作负载的代码，直接进行通信监视和管理
- 提供了统一的配置方式，用于管理服务之间的通信和边缘通信
- 除了支持Kubernetes，还支持多种底层平台

**问题**：在早期的时候又要部署微服务，又要部署Sidecar，对于运维人员来说较为困难，所以没有得到很好的发展，其实主要的问题是Linkerd只是实现了数据层面的问题，但没有对其进行管理。

> **数据层面**：通过Sidecar解决了数据处理的问题

### 总结

- 优点：

1.无需侵入业务代码就能管理服务流量，

2.兼容kubernetes提供的所有功能

- 缺点：

1.部署繁琐

2.只是实现数据层面的问题，没有对数据层面进行管理

## istio

由Google，IBM和Lyft共同发起的开源项目

```
官方对 istio 的介绍浓缩成了一句话：
An open platform to connect, secure, control and observe services.
翻译："连接、安全加固、控制和观察服务的开放平台"。开放平台就是指它本身是开源的，服务对应的是微服务，也可以粗略地理解为单个应用。
```

![](http://myimg.go2flare.xyz/img/image-20220221034112006.png)

### 概念

Istio 是一个开源服务网格，它透明地分层到现有的分布式应用程序上。 Istio 强大的特性提供了一种统一和更有效的方式来保护、连接和监视服务。

**Istio 是实现负载平衡、服务到服务身份验证和监视的路径——只需要很少或不需要更改服务代码**。它强大的控制平面带来了重要的特点，包括：

- 使用 TLS 加密、强身份认证和授权的集群内服务到服务的安全通信

- 自动负载均衡的 HTTP，gRPC，WebSocket，和 TCP 流量

- 通过丰富的路由规则、重试、故障转移和故障注入对流量行为进行细粒度控制

- 一个可插入的策略层和配置 API，支持访问控制、速率限制和配额

- 对集群内的所有流量(包括集群入口和出口)进行自动度量、日志和跟踪


Istio 是为可扩展性而设计的，可以处理不同范围的部署需求。Istio 的控制平面运行在 Kubernetes 上，你可以将部署在该集群中的应用程序添加到您的网格中，将网格扩展到其他集群，甚至连接 VM 或运行在 Kubernetes 之外的其他端点。

### 工作说明

Istio 由两个部分组成：**控制平面和数据平面**。

​		数据平面是业务之间的通信平面。如果没有一个服务网格，网络就无法理解正在发送的流量，也无法根据它是哪种类型的流量，或者它从谁那里来，到谁那里去做出任何决定。

- 服务网格使用代理拦截所有的网络流量，允许根据您设置的配置提供广泛的应用程序感知功能。


- 代理与您在集群中启动的每个服务一起部署，或者与运行在虚拟机上的服务一起运行。


- 控制平面获取您所需的配置和服务视图，并动态地对代理服务器进行编程，随着规则或环境的变化更新它们。


### 特点

**Sidecar作为为独立部署的进程**
sidecar降低应用程序代码和底层代码的耦合度，帮助异构服务通过sidecar快速接入微服务体系。

以下的四个动词就是 istio 的主要功能，官方也各有一句话的说明。这里再阐释一下：

**连接（Connect）**：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能

**安全加固（Secure）**：自动为服务之间的调用提供认证、授权和加密

**控制（Control）**：应用用户定义的 policy，保证资源在消费者中公平分配

**观察（Observe）**：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况

### 架构分析

以下是 istio 官方给出的架构图：

![在这里插入图片描述](https://img-blog.csdnimg.cn/3bd583864de949cc86012444630e10ea.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGL6YeM5omT5Lye5bGL5aSW5LmY5YeJ,size_12,color_FFFFFF,t_70,g_se,x_16)

可以看到，istio 就是我们上述提到的 service mesh 架构的一种实现，服务之间的通信（比如这里的 Service A 访问 Service B）会通过代理（默认是 envoy）来进行，而且中间的网络协议支持 HTTP/1.1，HTTP/2，gRPC 或者 TCP，可以说覆盖了主流的通信协议。控制中心做了进一步的细分，分成了 Pilot、Mixer、和 Citadel，它们的各自功能如下：

Pilot：为 envoy 提供了服务发现，流量管理和智能路由（AB测试、金丝雀发布等），以及错误处理（超时、重试、熔断）功能。用户通过 pilot 的 API 管理网络相关的资源对象，pilot 会根据用户的配置和服务的信息把网络流量管理变成 envoy 能识别的格式分发到各个 sidecar 代理中。

Mixer：为整个集群执行访问控制（哪些用户可以访问哪些服务）和 policy 管理（rate limit，quota 等），并且收集代理观察到的服务之间的流量统计数据

Citadel：为服务之间提供认证和证书管理，可以让服务自动升级成 TLS 协议

代理会和控制中心通信，一方面可以获取需要的服务之间的信息，另一方面也可以汇报服务调用的 metrics 数据。知道 istio 的核心架构，再来看看它的功能描述就非常容易理解了。

连接：控制中心可以从集群中获取所有服务的信息，并分发给代理，这样代理就能根据用户的期望来完成服务之间的通信（自动地服务发现、负载均衡、流量控制等）

安全加固：因为所有的流量都是通过代理的，那么代理接收到不加密的网络流量之后，可以自动做一次封装，把它升级成安全的加密流量

控制：用户可以配置各种规则（比如 RBAC 授权、白名单、rate limit 或者 quota 等），当代理发现服务之间的访问不符合这些规则，就直接拒绝掉

观察：所有的流量都经过代理，因此代理对整个集群的访问情况知道得一清二楚，它把这些数据上报到控制中心，那么管理员就能观察到整个集群的流量情况了

### istio 解决什么问题

虽然看起来非常炫酷，功能也很强大，但是一个架构和产品出来都是要解决具体的问题。所以这部分我们来看看微服务架构中的难题以及 istio 给出的答案。

#### 服务监控

首先，原来的单个应用拆分成了许多分散的微服务，它们之间相互调用才能完成一个任务，而一旦某个过程出错（组件越多，出错的概率也就越大），就非常难以排查。

用户请求出现问题无外乎两个问题：错误和响应慢。如果请求错误，那么我们需要知道哪个步骤出错了，这么多的微服务之间的调用怎么确定哪个有调用成功？哪个没有调用成功呢？如果是请求响应太慢，我们就需要知道到底哪些地方比较慢？整个链路的调用各阶段耗时是多少？哪些调用是并发执行的，哪些是串行的？这些问题需要我们能非常清楚整个集群的调用以及流量情况。

#### 服务治理

此外，微服务拆分成这么多组件，如果单个组件出错的概率不变，那么整体有地方出错的概率就会增大。服务调用的时候如果没有错误处理机制，那么会导致非常多的问题。

比如如果应用没有配置超时参数，或者配置的超时参数不对，则会导致请求的调用链超时叠加，对于用户来说就是请求卡住了；如果没有重试机制，那么因为各种原因导致的偶发故障也会导致直接返回错误给用户，造成不好的用户体验；此外，如果某些节点异常（比如网络中断，或者负载很高），也会导致应用整体的响应时间变长，集群服务应该能自动避开这些节点上的应用；最后，应用也是会出现 bug 的，各种 bug 会导致某些应用不可访问。这些问题需要每个应用能及时发现问题，并做好对应的处理措施。

应用数量的增多，对于日常的应用发布来说也是个难题。应用的发布需要非常谨慎，如果应用都是一次性升级的，出现错误会导致整个线上应用不可用，影响范围太大；而且，很多情况我们需要同时存在不同的版本，使用 AB 测试验证哪个版本更好；如果版本升级改动了 API，并且互相有依赖，那么我们还希望能自动地控制发布期间不同版本访问不同的地址。这些问题都需要智能的流量控制机制。

#### 服务授权认证

为了保证整个系统的安全性，每个应用都需要实现一套相似的认证、授权、HTTPS、限流等功能。一方面大多数的程序员对安全相关的功能并不擅长或者感兴趣，另外这些完全相似的内容每次都要实现一遍是非常冗余的。这个问题需要一个能自动管理安全相关内容的系统。

### 用什么姿势接入 istio？

虽然 istio 能解决那么多的问题，但是引入 istio 并不是没有代价的。最大的问题是 istio 的复杂性，强大的功能也意味着 istio 的概念和组件非常多，要想理解和掌握 istio ，并成功在生产环境中部署需要非常详细的规划。一般情况下，集群管理团队需要对 kubernetes 非常熟悉，了解常用的使用模式，然后采用逐步演进的方式把 istio 的功能分批掌控下来。

第一步，自然是在测试环境搭建一套 istio 的集群，理解所有的核心概念和组件。了解 istio 提供的接口和资源，知道它们的用处，思考如何应用到自己的场景中，然后是熟悉 istio 的源代码，跟进社区的 issues，了解目前还存在的 issues 和 bug，思考如何规避或者修复。这一步是基础，需要积累到 istio 安装部署、核心概念、功能和缺陷相关的知识，为后面做好准备。

第二步，可以考虑接入 istio 的观察性功能，包括 logging、tracing、metrics 数据。应用部署到集群中，选择性地（一般是流量比较小，影响范围不大的应用）为一些应用开启 istio 自动注入功能，接管应用的流量，并安装 prometheus 和 zipkin 等监控组件，收集系统所有的监控数据。

这一步可以试探性地了解 istio 对应用的性能影响，同时建立服务的性能测试基准，发现服务的性能瓶颈，帮助快速定位应用可能出现的问题。此时，这些功能可以是对应用开发者透明的，只需要集群管理员感知，这样可以减少可能带来的风险。

第三步，为应用配置 timeout 超时参数、自动重试、熔断和降级等功能，增加服务的容错性。这样可以避免某些应用错误进行这些配置导致问题的出现，这一步完成后需要通知所有的应用开发者删除掉在应用代码中对应的处理逻辑。这一步需要开发者和集群管理员同时参与。

第四步，和 ingress、helm、应用上架等相关组件和流程对接，使用 istio 接管应用的升级发布流程。让开发者可以配置应用灰度发布升级的策略，支持应用的蓝绿发布、金丝雀发布以及 AB 测试。

第五步，接入安全功能。配置应用的 TLS 互信，添加 RBAC 授权，设置应用的流量限制，提升整个集群的安全性。因为安全的问题配置比较繁琐，而且优先级一般会比功能性相关的特性要低，所以这里放在了最后。

当然这个步骤只是一个参考，每个公司需要根据自己的情况、人力、时间和节奏来调整，找到适合自己的方案。

### 扩展 Istio 服务网格

下一个问题是关于扩展 Istio 服务网格的。目前官方社区给出的方案是使用 WebAssembly，目前这种扩展方式在国内用的还比较少，而且性能也堪忧。我观察到的大部分解决方案都是自定义 CRD，基于 Istio 构建服务网格管理平面。

另外，让 Istio 支持异构环境，适用于一切工作负载，如虚拟机、容器，这个对于终端用户来说也有很强的需求，因为这可以让用户很方便的从传统负载迁移应用到服务网格中。最后是多集群、多网格的混合云流量管理，这个属于比较高阶的需求了。

## Istio 开源生态

下表中罗列的是基于 Istio 的开源项目。

![img](https://pic2.zhimg.com/80/v2-ba4ea0a0aed2f455d390969ac143acd1_720w.jpg)

​		发掘从 2017 年 5 月 Istio 开源至今也有 4 年多了，虽然该项目在 GitHub 上已经有很高的关注度，并发布了 10 几个版本，但其开源生态还在萌芽期。这张表列举了 Istio 生态中的开源项目，统计截止到 2021 年 11 月 11 日，表格按照开源时间排序。这些项目在 Istio 服务网格之上增强了网关、扩展和实用工具等。以下挑选其中 2 个来着重分享下。

### Slime：基于 Istio 的智能服务网格管理器

Slime 是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器。Slime 基于 Kubernetes Operator 实现，可作为 Istio 的 CRD 管理器，无缝对接 Istio，无须做任何定制化改造，定义动态的服务治理策略，从而达到自动便捷使用 Istio 和 Envoy 高阶功能的目的。

Slime 试图解决以下问题：

- 在 Istio 中如何实现高阶扩展的问题，比如扩展 HTTP 插件，限流功能比较单薄，无法根据服务的资源使用率做到自适应限流
- 解决 Sidecar 配置全量下发消耗大量资源导致应用性能变差的问题

Slime 解决以上问题的答案是构建 Istio 的管理平面，其核心思路是：

- 构建可拔插控制器
- 数据平面监控
- CRD 转换

下图是 Istio 作为 Istio 管理平面的流程图。



![img](https://pic2.zhimg.com/80/v2-7b6fc8612ba89617ff13ca4e355a6021_720w.jpg)



Slime 管理 Istio 的具体步骤如下：

1. Slime Operator 根据管理员的配置在 Kubernetes 中完成 Slime 组件的初始化；
2. 开发者创建符合 Slime CRD 规范的配置并应用到 Kubernetes 集群中；
3. Slime 查询 Prometheus 中保存的相关服务的监控数据，结合 Slime CRD 中自适应部分的配置，将 Slime CRD 转换为 Istio CRD，同时将其推送到 Global Proxy 中；
4. Istio 监听 Istio CRD 的创建；
5. Istio 将 Sidecar Proxy 的配置信息推送到数据平面相应的 Sidecar Proxy 中；

下图展示的 Slime 的内部架构图。



![img](https://pic4.zhimg.com/80/v2-fe1c05a0929484c47f93ccd6571dc19b_720w.jpg)



作为 Istio 的管理平面，可以将 Slime 的核心看做是 Istio 的一个 Operator。

Slime 内部分为三大组件：

- **slime-boot**：在 Kubernetes 上部署 Slime 模块的 operator。
- **slime-controller**：Slime 的核心组件，监听 Slime CRD 并将其转换为 Istio CRD。
- **slime-metric**：用于获取服务 metrics 信息的组件，slime-controller 会根据其获取的信息动态调整服务治理规则。

下图展示的是 Slime 自适应限流的架构图。



![img](https://pic4.zhimg.com/80/v2-325209b4940bbb254e0ee0ad8b40e50f_720w.jpg)



Envoy 内置的限流组件功能单一，只能以实例维度配置限流值，无法做到根据应用负载的自适应限流。Slime 通过与 Prometheus metric server 对接，实时的获取监控情况，来动态配置限流值。

Slime 的自适应限流的流程分为两部分，一部分为 SmartLimiter 到 [EnvoyFilter](https://link.zhihu.com/?target=https%3A//istio.io/latest/docs/reference/config/networking/envoy-filter/) 的转换，另一部分为获取监控数据。目前 Slime 支持从 Kubernetes Metric Server 获取服务的 CPU、内存、副本数等数据。Slime 还对外提供了一套监控数据接口（Metric Discovery Server），通过 MDS，可以将自定义的监控指标同步给限流组件。

Slime 创建的 CRD SmartLimiter 用于配置自适应限流。其的配置是接近自然语义，例如希望在 CPU 超过 80% 时触发服务 A 的访问限制，限额为 30QPS，对应的 SmartLimiter 定义如下：

```yaml
apiVersion: microservice.netease.com/v1alpha1
kind: SmartLimiter
metadata:
  name: a
  namespace: default
spec:
  descriptors:
  - action:
      fill_interval:
        seconds: 1
      quota: "30/{pod}"    # 30 为该服务的额度，将其均分给每个 pod，加入有 3 个 pod，则每个 pod 的限流为 10
    condition: "{cpu}>0.8" # 根据监控项{cpu}的值自动填充该模板
```

### Aeraki：非侵入式的 Istio 扩展工具集

Aeraki 是腾讯云在 2021 年 3 月开源的，它的架构与 Slime 类似。它从 Istio 中拉取服务数据，根据 ServiceEntry 和流量规则生成 Envoy 配置，也就是 EnvoyFilter 推送到 Istio 中。简而言之，你可以把 Aeraki 看做 Istio 中管理的七层协议的 Operator。

下图是 Aeraki 的架构图。



![img](https://pic2.zhimg.com/80/v2-1ba297f22e94f97674b21153ef42ec65_720w.jpg)



来源：[https://cloudnative.to/blog/istiocon-layer7-traffic/](https://link.zhihu.com/?target=https%3A//cloudnative.to/blog/istiocon-layer7-traffic/)

Aeraki 作为一个独立组件部署，可以很方便地作为一个插件和 Istio 进行集成。

Aeraki 可以根据 Istio 版本和 Kubernetes 集群相关信息自动进行调整配置，避免了 EnvoyFilter 的手动创建和维护工作。Aeraki 创建了面向七层协议 CRD 隐藏了 Envoy 的配置细节，屏蔽了不同 Istio 版本生成的缺省 Envoy 配置的差异，对于运维非常友好。

## 服务网格选型对比-Istio、Linkerd、Consul Connect

Istio、Linkerd和[Consul](https://so.csdn.net/so/search?q=Consul&spm=1001.2101.3001.7020) Connect。它们都是拥有活跃社区的开源产品。基于他们的愿景和实施，他们也都有各自的优点和缺点。

### Istio

Istio是[kubernetes](https://so.csdn.net/so/search?q=kubernetes&spm=1001.2101.3001.7020)原生的服务网格，最初由Lyft开发，并被业界广泛使用。世界顶尖的云服务厂商都将其作为其服务的默认服务网格，最具代表的厂商有谷歌、IBM和微软等。Istio提供了一套极其强大的功能来创建服务之间的连接，包括请求路由、超时、断路和故障注入。此外，Istio通过延迟、流量和错误等指标对应用程序进行了深入的监控。
![在这里插入图片描述](https://img-blog.csdnimg.cn/3bd583864de949cc86012444630e10ea.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bGL6YeM5omT5Lye5bGL5aSW5LmY5YeJ,size_12,color_FFFFFF,t_70,g_se,x_16)

**优势：**

- 拥有最活跃的社区
- 业界采用率高
- 与Kubernetes和虚拟机一起使用

**劣势：**

- 学习使用难度逐步升高
- 集群开销大
- 缺乏本地管理仪表板

### Linkerd

Linkerd是是第二大流行的服务网格，是云原生计算基金会（CNCF）的一部分。
架构上Linkerd与Istio并无太大区别，但它比Istio更灵活，可以支持可插拔架构的多个维度。例如：nginx、Traefik和Kong，还有Grafana、Prometheus和Jaeger合作体现其可观察性。

**优势：**

- 简单易用，使用的企业多

**劣势：**

- 仅适用于Kubernetes，不支持虚拟机中的某些网络路由功能，例如断路或速率限制

### Consul Connect

Consul是分布式应用中最流行的服务发现和键/值存储，直到其母公司HashiCorp以Consul Connect的名义转换为服务网格。
Consul是用Go语言开发，从安全性及连接性来讲，它与前两款产品无太大分别，但是它的配置十分简便，复杂性更低。

**优势：**

- 有HashiCorp的支持和企业级支持的可用性，同时支持虚拟机和Kubernetes。

**劣势：**

- 开源社区有限，缺乏完整和易于理解的文档

### 对比分析

| 对比项                     | Istio                    | Linkerd    | Consul Connect           |
| -------------------------- | ------------------------ | ---------- | ------------------------ |
| 支持的平台                 | Kubernetes 和虚拟机      | Kubernetes | Kubernetes和虚拟机       |
| 支持的 Ingress 控制器      | Istio ingress            | 任意       | Envoy                    |
| 流量管理功能               | 蓝绿部署、断路和速率控制 | 蓝绿部署   | 蓝绿部署、断路和速率控制 |
| Prometheus 和 Grafana 支持 | 是                       | 是         | 否                       |
| 混沌测试                   | 是                       | 是         | 否                       |
| 管理复杂度                 | 高                       | 低         | 中                       |
| 原生 GUI                   | 否                       | 是         | 是                       |

### 总结

在 k8s 中，服务的可靠性由 k8s 保证，用不着服务发现，而Consul一般用作服务发现和配置中心。一般有三种情况：

1. 仅用做服务注册和发现，那么在K8S中去掉Consul是可以的，需求只是可以服务发现的话，直接用K8S中的service就够了。只依赖kube proxy，使用K8S本身的service做服务发现即可。
2. 仅做配置中心，因K8S本身不具备配置管理的功能，所以不能去掉，直接将Consul运行在K8S中即可。
3. 即做服务发现，又做配置中心。这种情况比较复杂，将服务发现功能转移到K8S，保留配置中心的功能也是一种办法，但修改成本可能比较高，需要仔细评估。

另外，kube这个功能还是有很多局限性的，性能、健康检查、容错等方面做得比较基础。但也够用。好处是对应用完全无侵入。

在K8S中的服务发现，如果不使用K8S本身的机制，需要注意的一点是service和kube-proxy无法感知和操作应用的流量，在针对deployment/statefulset等对象进行升级时，无法直接使用rolling update的平滑升级方式。这一点在应用升级时需要特别注意，要根据应用自身的服务发现和负载均衡机制来制定平滑升级模式，相对来讲版本发布就会变得更复杂。

通常的做法，在小规模微服务（即20个及以下的应用）环境，一般建议使用K8S原生的服务发现。现在K8S的生态中，特别是由于service mesh的趋近成熟，像Spring Clound这样的较重的微服务框架能提供的高级功能（比如熔断、全链路监控、API网关、服务路由等）都有了另外一种基于Kubernetes原生的非侵入式的解决方案

kubernetes部署微服务，让服务实例可以自由的伸缩，如果服务间有grpc调用，kubernetes无法实现grpc的负载均衡，istio就犹如雪中送碳，istio既可以提供服务发现的服务，同时其他的功能可以和K8S互补，如版本控制，流量策略，非侵入式的服务监控，最重要的是使用istio可以将不用语言开发的微服务轻松结合起来，kubernetes+istio应该是目前的最好方案

## 服务网格的未来发展

### 让 Istio 适用于一切环境和一切工作负载

我们看到了网易、腾讯主要是通过构建 Operator 来扩展 Istio，然而这种扩展对于多集群管理来说并不够用。我们知道我们目前的基础设施很多是在向云原生化或者是容器化转型，那么就存在一个容器、虚拟机等共存的环境。这就是异构环境，这些不同环境的流量如何统一管理呢？其实使用 Istio 是可以做到的。同样是要在 Istio 之上构建一个管理平面，并增加一个抽象层，增加适用于集群管理的 CRD，比如集群流量配置、集群策略配置等。另外还要在每个集群中部署一个 Gateway，统一连接到一个边缘代理，让所有的集群互联。这也是 Tetrate Service Bridge 的产品理念。

下图展示的 [Tetrate Service Bridge](https://link.zhihu.com/?target=https%3A//www.tetrate.io/tetrate-service-bridge/) 架构图。



![img](https://pic3.zhimg.com/80/v2-0dc93f1bf4048dd4e882a797e3c846e2_720w.jpg)



### API 网关与服务网格的融合

下图展示了使用 Istio Gateway、Kubernetes Ingress、API Gateway 及 NodePort/LB 暴露 Istio mesh 中服务的四种方式。



![img](https://pic1.zhimg.com/80/v2-a8abbb3562ea3e28d193905bdcf5cef0_720w.jpg)

其中阴影表示的是 Istio mesh，mesh 中的的流量属于集群内部（东西向）流量，而客户端访问 Kubernetes 集群内服务的流量属于外部（南北向）流量。不过因为 Ingress、Gateway 也是部署在 Kubernetes 集群内的，这些节点访问集群内其他服务的流量就难以归属了。

在 Istio mesh 中你可以使用多种 Kubernetes Ingress Controller 来充当入口网关，当然你还可以直接使用 Istio 内置的 Istio 网关，对于策略控制、流量管理和用量监控可以直接通过 Istio 网关来完成，这样做的好处是通过 Istio 的控制平面来直接管理网关，而不需要再借助其他工具。但是对于 API 声明周期管理、复杂的计费、协议转换和认证等功能，传统的 API 网关可能更适合你。所以，你可以根据自己的需求来选择，也可以组合使用。

下表中列出了 Istio Mesh 中暴露服务的四种方式。

![img](https://pic2.zhimg.com/80/v2-d802459f5109f5cecf3b758095285f51_720w.jpg)

目前有些传统的反向代理也在向 Service Mesh 方向发展，如 Nginx 构建了 Nginx Service Mesh，Traefik 构建了 Traefik Mesh。还有的 API 网关产品也向 Service Mesh 方向挺进，比如 Kong 发展出了 Kuma。在未来，我们会看到更多 API 网关、反向代理和服务网格的融合产品出现。

# istio部署

## 部署Istio

### 获取istio包
```
wget https://github.com/istio/istio/releases/download/1.9.3/istio-1.9.3-linux-amd64.tar.gz
```

如果获取失败，可直接到官网下载后上传

https://github.com/istio/istio/releases/tag/1.9.3

### 解压缩

```
tar -xf istio-1.9.3-linux-amd64.tar.gz 

# 拷贝istioctl文件至/usr/bin或者配置环境变量也可

```

### 移动到 Istio 包目录

```
cd istio-1.9.3
cp bin/istioctl /usr/local/bin/
```

安装目录包含：

- 示例应用程序 `samples/`
- 目录中的客户端二进制 文件。[`istioctl`](https://istio.io/latest/docs/reference/commands/istioctl)`bin/`

将`istioctl`客户端添加到您的路径（Linux 或 macOS）：

```
export PATH=$PWD/bin:$PATH
```

### 查看istio可选的几种部署模式

```
$ istioctl profile list
Istio configuration profiles:
    demo
    empty
    minimal
    preview
    remote
    default
```

这里测试环境用的profile是minimal

**profile开启的组件、插件的表格如下**

|                        | default                               | demo                               | minimal               | remote                                     | empty                    | preview  |
| ---------------------- | ------------------------------------- | ---------------------------------- | --------------------- | ------------------------------------------ | ------------------------ | -------- |
| **Core components**    |                                       |                                    |                       |                                            |                          |          |
| `istio-egressgateway`  |                                       | √                                  |                       |                                            |                          |          |
| `istio-ingressgateway` | √                                     | √                                  |                       | √                                          |                          | √        |
| `istio-pilot`          | √                                     | √                                  | √                     | √                                          |                          | √        |
| **Addons**             |                                       |                                    |                       |                                            |                          |          |
| `grafana`              |                                       | √                                  |                       |                                            |                          |          |
| `istio-tracing`        |                                       | √                                  |                       |                                            |                          |          |
| `kiali`                |                                       | √                                  |                       |                                            |                          |          |
| `prometheus`           | √                                     | √                                  |                       | √                                          |                          | √        |
| **Description**        | 是官方推荐的 istio 安装 profile的方式 | 仅供学习使用，并不合适作为生产环境 | 仅仅开启了 pilot 组件 | 提供共享控制面去操作多集群服务网格，不常用 | 不会开启任何组件或者插件 | 不太了解 |



## 安装 Istio

1. 对于本次安装，我们采用 `demo` [配置组合](https://www.bookstack.cn/read/istio-1.9-zh/97ab4a56105cbc92.md)。 选择它是因为它包含了一组专为测试准备的功能集合，另外还有用于生产或性能测试的配置组合。

   如果你的平台有供应商提供的配置组合，比如：Openshift，则在下面命令中替换掉 `demo` 配置项。更多细节请参阅你的 [平台说明](https://www.bookstack.cn/read/istio-1.9-zh/83e55c6b39360a08.md)

   ```
   $ istioctl install --set profile=demo -y
   ✔ Istio core installed✔ Istiod installed
   ✔ Egress gateways installed
   ✔ Ingress gateways installed
   ✔ Installation complete
   ```

2. 给命名空间添加标签，指示 Istio 在部署应用的时候，自动的注入 Envoy 边车代理：

   ```
   $ kubectl label namespace default istio-injection=enablednamespace/default labeled
   ```

## 部署示例应用

1. 部署 [`Bookinfo` 示例应用](https://www.bookstack.cn/read/istio-1.9-zh/cd39603369c70abb.md):

   [Zip](https://raw.githubusercontent.com/istio/istio/release-1.9/samples/bookinfo/platform/kube/bookinfo.yaml)

   ```
   $ kubectl apply -f @samples/bookinfo/platform/kube/bookinfo.yaml@service/details createdserviceaccount/bookinfo-details createddeployment.apps/details-v1 createdservice/ratings createdserviceaccount/bookinfo-ratings createddeployment.apps/ratings-v1 createdservice/reviews createdserviceaccount/bookinfo-reviews createddeployment.apps/reviews-v1 createddeployment.apps/reviews-v2 createddeployment.apps/reviews-v3 createdservice/productpage createdserviceaccount/bookinfo-productpage createddeployment.apps/productpage-v1 created
   ```

2. 应用很快会启动起来。当一个个的 Pod 准备就绪，ISTIO 边车代理将伴随他们一起部署。

   ```
   $ kubectl get servicesNAME          
   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGEdetails       ClusterIP   10.0.0.212      <none>        9080/TCP   29skubernetes    ClusterIP   10.0.0.1        <none>        443/TCP    25mproductpage   ClusterIP   10.0.0.57       <none>        9080/TCP   28sratings       ClusterIP   10.0.0.33       <none>        9080/TCP   29sreviews       ClusterIP   10.0.0.28       <none>        9080/TCP   29s
   ```

   和

   ```
   $ kubectl get podsNAME                              READY   STATUS    RESTARTS   AGEdetails-v1-558b8b4b76-2llld       2/2     Running   0          2m41sproductpage-v1-6987489c74-lpkgl   2/2     Running   0          2m40sratings-v1-7dc98c7588-vzftc       2/2     Running   0          2m41sreviews-v1-7f99cc4496-gdxfn       2/2     Running   0          2m41sreviews-v2-7d79d5bd5d-8zzqd       2/2     Running   0          2m41sreviews-v3-7dbcdcbc56-m8dph       2/2     Running   0          2m41s
   ```

   重新运行前面的命令，在执行下面步骤之前，要等待并确保所有的 Pod 达到此状态： 就绪状态（READY）的值为 `2/2` 、状态（STATUS）的值为 `Running` 。 基于你平台的不同，这个操作过程可能会花费几分钟的时间。

3. 验证方方面面均工作无误。运行下面命令，通过检查返回的页面标题，来验证应用是否已在集群中运行，并已提供网页服务：

   ```
   $ kubectl exec "$(kubectl get pod -l app=ratings -o jsonpath='{.items[0].metadata.name}')" -c ratings -- curl -s productpage:9080/productpage | grep -o "<title>.*</title>"<title>Simple Bookstore App</title>
   ```

## 对外开放应用程序

此时，BookInfo 应用已经部署，但还不能被外界访问。 要开放访问，你需要创建 [Istio 入站网关（Ingress Gateway）](https://www.bookstack.cn/read/istio-1.9-zh/bffe82639592b59c.md#gateways), 它会在网格边缘把一个路径映射到路由。

1. 把应用关联到 Istio 网关：

   [Zip](https://raw.githubusercontent.com/istio/istio/release-1.9/samples/bookinfo/networking/bookinfo-gateway.yaml)

   ```
   $ kubectl apply -f @samples/bookinfo/networking/bookinfo-gateway.yaml@gateway.networking.istio.io/bookinfo-gateway createdvirtualservice.networking.istio.io/bookinfo created
   ```

2. 确保配置文件没有问题：

   ```
   $ istioctl analyze✔ No validation issues found when analyzing namespace: default.
   ```

### 确定入站 IP 和端口

按照说明，为访问网关设置两个变量：`INGRESS_HOST` 和 `INGRESS_PORT`。 使用标签页，切换到你选用平台的说明：

设置入站端口：

```
$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="http2")].nodePort}')$ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}')
```

确认端口被成功的赋值给了每一个环境变量：

```
$ echo "$INGRESS_PORT"32194
$ echo "$SECURE_INGRESS_PORT"31632
```

设置入站 IP：

```
$ export INGRESS_HOST=$(minikube ip)
```

确认 IP 地址被成功的赋值给了环境变量：

```
$ echo "$INGRESS_HOST"192.168.4.102
```

在一个新的终端窗口中执行此命令，启动一个 Minikube tunnel，它将把流量发送到你 Istio 入站网关：

```
$ minikube tunnel
```

执行下面命令进行判断：你的 Kubernetes 集群环境是否支持外部负载均衡：

```
$ kubectl get svc istio-ingressgateway -n istio-systemNAME                   TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                                      AGEistio-ingressgateway   LoadBalancer   172.21.109.129   130.211.10.121  80:31380/TCP,443:31390/TCP,31400:31400/TCP   17h
```

设置 `EXTERNAL-IP` 的值之后， 你的环境就有了一个外部的负载均衡，可以用它做入站网关。 但如果 `EXTERNAL-IP` 的值为 `<none>` (或者一直是 `<pending>` 状态)， 则你的环境则没有提供可作为入站流量网关的外部负载均衡。 这个情况，你还可以用服务（Service）的 [节点端口](https://kubernetes.io/zh/docs/concepts/services-networking/service/#nodeport) 访问网关。

依据你的环境，选择相应的说明：

**如果你确定你的环境中确实存在外部的负载均衡，请跟随下面的说明.**

设置入站 IP 地址和端口

```
$ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="http2")].port}')$ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="https")].port}')
```

在某些环境中，负载均衡除了 IP 地址，还可以用主机名访问。 在这种情况下，入站流量网关的`EXTERNAL-IP` 值不是 IP 地址，而是一个主机名， 那上面设置 `INGRESS_HOST` 环境变量的操作会失败。 使用下面命令纠正 `INGRESS_HOST` 的值。

```
$ export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
```

**按照下面说明：如果你的环境中没有负载均衡，那就选择一个节点端口来代替.**

设置入站的端口：

```
$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="http2")].nodePort}')$ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="https")].nodePort}')
```

*GKE:*

```
$ export INGRESS_HOST=workerNodeAddress
```

你需要创建一个防火墙规则，放行发往 `ingressgateway` 的 TCP 流量。 再运行下面的命令，单独放行发往 HTTP 端口或 HTTPS 端口的流量，或者都放行。

```
$ gcloud compute firewall-rules create allow-gateway-http --allow "tcp:$INGRESS_PORT"$ gcloud compute firewall-rules create allow-gateway-https --allow "tcp:$SECURE_INGRESS_PORT"
```

*IBM Cloud Kubernetes Service:*

```
$ ibmcloud ks workers --cluster cluster-name-or-id$ export INGRESS_HOST=public-IP-of-one-of-the-worker-nodes
```

*Docker For Desktop:*

```
$ export INGRESS_HOST=127.0.0.1
```

*Other environments:*

```
$ export INGRESS_HOST=$(kubectl get po -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].status.hostIP}')
```

1. 设置环境变量 `GATEWAY_URL`:

   ```
   $ export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT
   ```

2. 确保 IP 地址和端口均成功的赋值给了环境变量:

   ```
   $ echo "$GATEWAY_URL"192.168.99.100:32194
   ```

### 验证外部访问

用浏览器查看 Bookinfo 应用的产品页面，验证 Bookinfo 已经实现了外部访问。

1. 运行下面命令，获取 Bookinfo 应用的外部访问地址。

   ```
   $ echo "http://$GATEWAY_URL/productpage"
   ```

2. 把上面命令的输出地址复制粘贴到浏览器并访问，确认 Bookinfo 应用的产品页面是否可以打开。

## 查看仪表板

Istio 和[几个](https://www.bookstack.cn/read/istio-1.9-zh/70fe8d44fb2c69d1.md)遥测应用做了集成。 遥测能帮你了解服务网格的结构、展示网络的拓扑结构、分析网格的健康状态。

使用下面说明部署 [Kiali](https://istio.io/latest/zh/docs/ops/integrations/kiali/) 仪表板、 以及 [Prometheus](https://istio.io/latest/zh/docs/ops/integrations/prometheus/)、 [Grafana](https://istio.io/latest/zh/docs/ops/integrations/grafana)、 还有 [Jaeger](https://istio.io/latest/zh/docs/ops/integrations/jaeger/)

1. 安装 [Kiali 和其他插件](https://github.com/istio/istio/tree/release-1.9/samples/addons)，等待部署完成。

   ```
   $ kubectl apply -f samples/addons$ kubectl rollout status deployment/kiali -n istio-systemWaiting for deployment "kiali" rollout to finish: 0 of 1 updated replicas are available...deployment "kiali" successfully rolled out
   ```

   如果在安装插件时出错，再运行一次命令。 有一些和时间相关的问题，再运行就能解决。

2. 访问 Kiali 仪表板。

   ```
   $ istioctl dashboard kiali
   ```

3. 在左侧的导航菜单，选择 *Graph* ，然后在 *Namespace* 下拉列表中，选择 *default* 。

   Kiali 仪表板展示了网格的概览、以及 `Bookinfo` 示例应用的各个服务之间的关系。 它还提供过滤器来可视化流量的流动。

   [![Kiali Dashboard](https://static.sitestack.cn/projects/istio-1.9-zh/c4eae32aa070ced24ba57bf9c1ea3367.png)](https://istio.io/latest/zh/docs/setup/getting-started/kiali-example2.png)



## 某些人的看法

作者：纸昂
链接：https://www.zhihu.com/question/419175473/answer/2329267045
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



一项技术是否真正能大规模落地，取决于 ROI，即投入产出比。

### 成本

Service Mesh 这个事情，它的成本比较高，包括 初次使用成本和后期运维成本。

初次使用：由于国内企业的通信协议和服务状态和Istio宣传的理想状态差距较大，有不小的改造成本。

后期运维：

1. 成功用上Istio之后，要学习它一整套机制，需要有一整套运维知识。如果把Istio当做一个黑盒是完全没有办法的。
2. 数据面的性能差。默认使用iptables的消息劫持方式，这会使得每个请求的延时增加，对于容器也有更高的CPU、Mem消耗。
3. 控制面的性能和可扩展性差。规模变大之后，Istio的控制面就承受不了了。一般来看原生Istio最多能够承受100个服务，2000个容器这样大的量级。随着公司的发展，量级的增大，还得换技术？很多配置都在里面，怎么找兼容的技术呢？这完全无法承受。业界有一些按需加载的技术，可能可以提升Istio的容量，但根本上只是在打补丁而已。Istio的控制面与数据面之间的通信协议，从根本上就对大规模场景无效。

### 产出

这里看痛点到底有多痛，收益到底有多猛烈。

常见的收益有：

- 路由
- 服务治理（稳定性控制）
- 监控
- 安全

如果一家公司已经用了微服务好好的，可能也已经有一定的路由、治理、监控和安全的能力了，新增的能力也许有限。

还有一些其他痛点，譬如多语言之间的统一和协同。这不是每家企业都会遇到。

### 鸡肋

投入可以说是惨烈，产出相对受限。

真正有技术研发实力的公司，直接脱离Istio自己做了。国内互联网大厂落地较好的，都不是用Istio而是自研，或者对外说是Istio实际上不是那么回事。（Istio想要在百万容器量级的大厂落地，可能每个容器都需要1TB的内存 ^_^）

没有技术研发实力的公司，迁移成本非常大，收益还有限。落地的时候困难重重，运维更是可能会成为无底洞。

我觉得真正等Service Mesh 的春天到来，还是要等某个互联网大厂把内部落地很好的东西开源出来，对Istio形成降维打击。就像必须要有Borg才能有Kubernetes一样，深度实际论证过的东西要比只搞过book info sample 的要更加行之有效。否则落地、扩容、升级，举目之处皆瓶颈也。

# reference

> https://mp.weixin.qq.com/s?__biz=MzI1NTI3MzEwMg==&mid=2247509573&idx=1&sn=e5e8850a2b8e9930948eb0e6e06c0826&chksm=ea3a97a4dd4d1eb2ec61ebd212fd9844758cba9058c1b48c05e24fff0aeb0b6b43bae19061b6&mpshare=1&scene=1&srcid=0120tBbVbt0D0Gt5kGnFEG4A&sharer_sharetime=1642672395214&sharer_shareid=db789653b16f9e5ae5714aca1c15e4c5#rd
>
> https://www.zhihu.com/question/427722643
>
> https://zhuanlan.zhihu.com/p/61901608
>
> https://zhuanlan.zhihu.com/p/61901608
>
> https://zhuanlan.zhihu.com/p/353127287
>
> https://blog.csdn.net/weixin_40274679/article/details/106232119